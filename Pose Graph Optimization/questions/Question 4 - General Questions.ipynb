{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-confirmation",
   "metadata": {},
   "source": [
    "# Question 4: General Theory/Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-cleaners",
   "metadata": {},
   "source": [
    "_No need to be verbose, it's not fun for anyone_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-hindu",
   "metadata": {},
   "source": [
    "1. What part of S**L**A**M** did this project deal with? Why? What does the other part deal with and how would it generally work, given that you only have LIDAR scans, RGB video stream, and noisy pose data for a moving robot?\n",
    "\n",
    "\n",
    "2. Loop closures play an important role in reducing drift, how would you go about detecting these?\n",
    "\n",
    "\n",
    "3. Explain the structure of your Jacobian. Is the pose-graph fully connected? Why/Why not?\n",
    "\n",
    "\n",
    "4. With what you know now, how would you describe and differentiate the SLAM frontend and backend? Why do we need to optimise our poses/map in the first place - where does the noise come from/why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-bones",
   "metadata": {},
   "source": [
    "_Your Answer_\n",
    "#### Question 1\n",
    "Map optimization, Robust local motion estimation and Mapping and loop closure detection are the important components of the general Simultaneous Localisation and Mapping (SLAM) system. The part of SLAM used in this project is Graph-based SLAM and more specifically Graph optimization. It dealt with only optimizing the poses given the control inputs of the robot and not the map. The Graph-based SLAM can be considered as two different tasks as follows -\n",
    " - Graph construction, i.e. construction of graph based on the raw measurements. This is usually referred to as front-end and is heavily sensor dependent.\n",
    " - Graph optimization. This involves determining the most likely configuration of poses based on the edges of the graph, i.e. pose graph optimisation. This is the backend of SLAM. \n",
    "\n",
    "The other part would deal with optimizing the map from the given lidar scans, RGB video stream, and noisy pose data for a moving robot. The RGB lidar scans can be used to find the the correspondances between the two locations using which we would then calculate the transformation matrix (by ICP) and then optimize it.  \n",
    "SLAM incrementally processes and links the LIDAR scans in order to construct a pose graph. Scan matching is used to determine whether a place was previously visited by the robot. The robot may form closure loops along its path. For representing the environment as a Probabilistic Occupancy grid, occupancy maps can be built using optimised scans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c96b1d",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Loop closure involves the recognition of when the robot has returned to a previously mapped region and the use of this information to reduce the uncertainty in the map estimate. Three common loop closure detection techniques.\n",
    "- Map-to-Map: match geometric features within the map\n",
    "- Sensor-to-Sensor: match the latest sensor data to some previously acquired sensor data\n",
    "- Map-to-Sensor: match the latest sensor data to other regions of the map\n",
    "\n",
    "When searching for a landmark, a feature extraction process is used such that it can scan at high speeds. Some methods based on image features include bag of features (BoF) and bag of visual words (BoVW). Nowadays, deep learning is also used to compare distances from features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f23c92",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "<!-- <figure> -->\n",
    "<img src='../data/4.jpeg' alt=drawing width=500 height=600>\n",
    "<!-- <figure> -->\n",
    "<img src='../data/3.jpeg' alt=drawing width=500 height=600>\n",
    "We can say a pose graph is fully connected when from each pose every other pose can be located. Since we have n = 120 poses and m = 140 loop closure constraints, for a pose graph to be fully connected we would need n odometric constraints and (n-1)! loop closure constraints. But we have just 20 loop closure constraints. So, to make the graph fully connected we would require a lot of data and storing it would require lot of space as well. Also for a fully connected graph the optimization time will also be higher. Therefore it is better if graph is not fully connected.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26abf42b",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "SLAM frontend comprises of constructing graph from the sensor data while the back-end relies on an abstract representation of the data which is sensor agnostic. The optimization techniques focus on computing the best map given the constraints and are called SLAM back-ends. Simply put, SLAM frontend is graph construction and backend is graph optimization. \n",
    "\n",
    "SLAM front-ends seek to interpret the sensor data to obtain the constraints that are the basis for the optimization approaches. The main focus of the SLAM front-end is on finding constraints from an observation also called data association. SLAM backend discovers and processes long-term scene characteristics, from the data associations to facilitate the fusion of history information and hence have the potential to providing more accurate motion segmentation results.  \n",
    "\n",
    "ICP provides a method to compute the relative transformation between the two point clouds. But it only works when there is very less displacement between the two. Generally the sensor measurements are errorneous, which can lead to incorrect correspondances. As these initial measurents are in error, the calculated transform is highly likely to be incorrect. SLAM tries to overcome these drawbacks and allows robots to have the ability to simultaneously build up a map and localize itself in an unknown environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e91a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
