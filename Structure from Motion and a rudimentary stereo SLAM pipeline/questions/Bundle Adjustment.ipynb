{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bundle Adjustment\n",
    "\n",
    "Part of this assignment is based on scipy-cookbook. It will take around 2 hours to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Read the paper 'Building Rome in a Day' and briefly write about the fundamental idea behind the problem and solution. No need to be verbose, just write about the challenge with the task and how the pipeline is implemented (do not include details about performance/parallelization).**\n",
    "\n",
    "#### Idea:\n",
    "\n",
    "The paper presents a system that can match and reconstruct 3D scenes from extensive collections of photographs found by searching for a given city (e.g., Rome) on the Internet. Their system uses an array of novel parallel distributed matching and reconstruction algorithms designed to maximize parallelism at each stage in the pipeline and minimize serialization bottlenecks. Using this reconstruction, a city could be 'built' using considerable resources and data in a day or less. Another primary purpose was to scale the system appropriately based on the possible computational ability and the extent of the given problem. This system is one to two orders of magnitude larger than the most extensive results reported in the literature. The system has used the existing matching algorithms and SfM algorithms such as SIFT, bundle adjustment, etc.\n",
    "\n",
    "\n",
    "#### Challenges:\n",
    "Some of the difficulties encountered are:\n",
    "\n",
    "1. Structured data collected from the same calibrated camera at a constant sampling rate and different sensors, make the calculations more flexible. On the other hand, unstructured data is taken from different cameras, in changing lighting conditions, with significantly less geographic data and no camera calibration knowledge. As only unstructured information is available online, the primary problem is this. \n",
    "    \n",
    "2. The step in the pipeline involving pruning and verifyng matches using a RANSAC-based estimation of essential or fundamental matrix is computationally very heavy; we cannot implement this on all the image features and therefore need to be filtered before applying this process.\n",
    "    \n",
    "3. It was essential to choose good algorithms that would satisfy the requirement of optimized memory usage and I/O bandwidth while choosing algorithms that work well together, scale well and provide high performance. In some cases, the authors designed and implemented the algorithms themselves.\n",
    "4. Metadata such as the website and username are used to group images, which may or may not always be practical. A better strategy would exploit all the textual tags and geotags associated with the images to predict what images are likely to match and then distribute the data accordingly.\n",
    "5. Since multi-threading and parallelism are not implemented in all parts and rely on the redundancy in various images, scaling is a problem. More optimization is required in the way pictures are distributed for processing.\n",
    "6. The current system uses batch jobs. However, adding more images to extend the system could be more effective.\n",
    "7. The track generation process merges tracks based on shared features, and inconsistent tracks can be generated. In such cases, they drop the offending points from the track.\n",
    "8. We use the skeletal sets algorithm to find this minimal set, which computes a spanning collection of photographs that preserve important connectivity data in the image graph. A two-frame reconstruction is calculated for each matching image pair with known focal lengths.\n",
    "\n",
    "\n",
    "#### Implementing the pipeline:\n",
    "\n",
    "The essential steps include pre-processing, image-matching, track-generation, geometric estimation, and distributed Computing Engine.\n",
    "1. In pre-processing, the images are assigned to cluster nodes from a central store. This is done in order to download images without being affected by the experiments on-demand in fixed-size chunks to perform load balancing. After verifying the is done, we extract the EXIF tags and record the focal length. Next, larger images are downsampled with maintaining aspect ratios and scaling focal lengths. The subsequent steps include converting to grayscale, extracting SIFT features, and partitioning the images.\n",
    "2. For matching, a multi-stage matching scheme was used. Each stage involved a proposal and a verification step. The system determines a set of image pairs that share general scene elements, and the confirmation involves specific and extensive feature matching. Next, vocabulary trees and query expansion are used for proposals and a greedy bin-packing algorithm to choose images to transfer to each node for verification involving photometric matching between feature descriptors and determining the essential or fundamental matrix depending on the available information.\n",
    "3. For each connected component the run structure is generated after track generation. It is good to reconstruct a minimal subset of images capturing essential connectivity of scene geometry and match graph. Pose estimation and a final bundle adjustment for refining SFM estimates could be used for adding all the remaining images. A skeletal sets algorithm is used by the authors that computes the spanning set of images. This set is used for estimating SFM parameters of the resulting components. The algorithm yields a larger set of components.\n",
    "\n",
    "The main stages of the pipeline can be concluded to have initially a pre-processing, matching, and geometric estimation. The pipeline involves dividing N images on M processors. Next, SIFT is used for feature extraction, and vocabulary tree vector quantization and term frequency counting are performed further. Subsequently, document frequency counting, TFIDF computation, and information broadcast are completed. The match verification tasks are then distributed using a round-robin bin-packing. Eventually, the match verification and proposal expansion occur depending on the images found in connected components using the next best k2 matches per image. Later, additional distributed verification, four more rounds of query expansion and validation, and track merging from local verified matches, followed by track aggregation into C connected components. Image-related components and distributed merging finally distribute the tracks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**2. How is this task different from a SLAM problem?**\n",
    "\n",
    "SLAM or Simultaneous localization and mapping is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. Here, images are obtained and used for constructing or updating the map of an unknown environment. In the SLAM problem, the poses of the robot are optimized using the given odometric constraints. Map of the unknown environment is constructed/updated while simultaneously keeping track of the agent's location within the map. Visual simultaneous localization and mapping (vSLAM) is the process of calculating the position and orientation of a camera, with respect to its surroundings, while simultaneously mapping the environment. This is different from the problem described in the  paper because the paper does not involve any sort of localization.It revolves around finding and matching various images and reconstructing a 3D environment. The paper doesn't involve any \"real-time\" images from a moving robot to create the map unlike in SLAM. The paper deals with images and data collected from the internet to connect isolated components together and recreate various sections of the environment by assembling all the pieces of information together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "We have a set of points in real world defined by their coordinates $(X, Y, Z)$ in some apriori chosen \"world coordinate frame\". We photograph these points by different cameras, which are characterized by their orientation and translation relative to the world coordinate frame and also by focal length and two radial distortion parameters (9 parameters in total). Then we precicely measure 2-D coordinates $(x, y)$ of the points projected by the cameras on images. Our task is to refine 3-D coordinates of original points as well as camera parameters, by minimizing the sum of squares of reprojecting errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a dataset from http://grail.cs.washington.edu/projects/bal/ for this task. Feel free to choose any of the ones mentioned on the page. Take the smallest file from each dataset (you can choose any but it will take longer to run, consume more memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-12-03 21:55:48,053 - utils - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import copy\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://grail.cs.washington.edu/projects/bal/data/\"\n",
    "\n",
    "DATASET_NAME = \"venice/\"\n",
    "FILE_NAME = \"problem-89-110973-pre.txt.bz2\"\n",
    "\n",
    "URL = BASE_URL + DATASET_NAME + FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    urllib.request.urlretrieve(URL, FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bal_data(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as file:\n",
    "        n_cameras, n_points, n_observations = map(\n",
    "            int, file.readline().split())\n",
    "\n",
    "        camera_indices = np.empty(n_observations, dtype=int)\n",
    "        point_indices = np.empty(n_observations, dtype=int)\n",
    "        points_2d = np.empty((n_observations, 2))\n",
    "\n",
    "        for i in range(n_observations):\n",
    "            camera_index, point_index, x, y = file.readline().split()\n",
    "            camera_indices[i] = int(camera_index)\n",
    "            point_indices[i] = int(point_index)\n",
    "            points_2d[i] = [float(x), float(y)]\n",
    "\n",
    "        camera_params = np.empty(n_cameras * 9)\n",
    "        for i in range(n_cameras * 9):\n",
    "            camera_params[i] = float(file.readline())\n",
    "        camera_params = camera_params.reshape((n_cameras, -1))\n",
    "\n",
    "        points_3d = np.empty(n_points * 3)\n",
    "        for i in range(n_points * 3):\n",
    "            points_3d[i] = float(file.readline())\n",
    "        points_3d = points_3d.reshape((n_points, -1))\n",
    "\n",
    "    return camera_params, points_3d, camera_indices, point_indices, points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params, points_3d, camera_indices, point_indices, points_2d = read_bal_data(FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_params: (89, 9);\n",
      "points_3d: (110973, 3);\n",
      "camera_indices: (562976,); \n",
      "point_indices: (562976,); \n",
      "points_2d: (562976, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"camera_params: {camera_params.shape};\\npoints_3d: {points_3d.shape};\\n\"\n",
    "        f\"camera_indices: {camera_indices.shape}; \\npoint_indices: {point_indices.shape}; \\n\"\n",
    "        f\"points_2d: {points_2d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have numpy arrays:\n",
    "\n",
    "1. `camera_params` with shape `(n_cameras, 9)` contains initial estimates of parameters for all cameras. First 3 components in each row form a **rotation vector**, next 3 components form a translation vector, then a focal distance and two distortion parameters.\n",
    "2. `points_3d` with shape `(n_points, 3)` contains initial estimates of point coordinates in the world frame.\n",
    "3. `points_2d` with shape `(n_observations, 2)` contains measured 2-D coordinates of points projected on images in all the observations.\n",
    "4. `camera_ind` with shape `(n_observations,)` gives the index of the camera (from 0 to `n_cameras - 1`) associated with a particular observation.   \n",
    "5. `point_ind` with shape `(n_observations,)` contains indices of 3D points (from 0 to `n_points - 1`) involved in each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Point Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise `points_3d`. It may not look like 'Venice' or any building as we are working with a small subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pcd_cloud = o3d.geometry.PointCloud()\n",
    "pcd_cloud.points = o3d.utility.Vector3dVector(points_3d[:100000,:100000])\n",
    "o3d.visualization.draw_geometries([pcd_cloud])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pcd_2.png](./pcd_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many cameras and 3D points do we have? Calculate the number of parameters to estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cameras: 89\n",
      "n_points: 110973\n",
      "Total number of parameters to estimate: 333720\n",
      "Total number of residuals: 1125952\n"
     ]
    }
   ],
   "source": [
    "n_cameras = camera_params.shape[0]\n",
    "# points_3d = points_3d[:100000,:100000]\n",
    "# point_indices = point_indices[:100000]\n",
    "n_points = points_3d.shape[0]\n",
    "\n",
    "n = 9 * n_cameras + 3 * n_points\n",
    "m = 2 * points_2d.shape[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters to estimate: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a relatively small problem to reduce computation time, but scipy's algorithm is capable of solving much larger problems, although required time will grow proportionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the function which returns a vector of residuals. We use numpy vectorized computations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short review on Transformations\n",
    "\n",
    "Rodrigues Formula: $$\\mathbf{R}=\\cos \\theta \\mathbf{I}+(1-\\cos \\theta) \\mathbf{n n}^{\\mathrm{T}}+\\sin \\theta \\mathbf{n}^{\\wedge}$$\n",
    "If described by a rotation vector, assuming that the rotation axis is a unit length vector $\\mathbf{n}$ and the angle is $\\theta$, then the vector $\\theta \\mathbf{n}$ can also describe this rotation. Here, rot_vecs = $\\theta \\mathbf{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(points, rot_vecs):\n",
    "    \"\"\"Rotate points by given rotation vectors.\n",
    "    \n",
    "    Rodrigues' rotation formula is used.\n",
    "    \"\"\"\n",
    "    theta = np.linalg.norm(rot_vecs, axis=1)[:, np.newaxis] #np.newaxis converts this into a column vector.\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        v = rot_vecs / theta\n",
    "        v = np.nan_to_num(v)\n",
    "    dot = np.sum(points * v, axis=1)[:, np.newaxis]\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    \n",
    "    return (cos_theta * points) + ((1 - cos_theta) * v * dot) + (sin_theta * np.cross(v, points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short review on camera modelling & radial distortion\n",
    "\n",
    "\n",
    "\n",
    "- Each pixel moves radially away from (barrel) or towards (pincushion) the image center (c).\n",
    "- As a function of distance from $c: r_{c}^{2}=x_{c}^{2}+y_{c}^{2}$.\n",
    "- The shift $\\gamma$ can be modelled as: $\\gamma=1+k_{1} r_{c}^{2}+k_{2} r_{c}^{4}$ where ${k}_{1}$ and ${k}_{2}$ are radial distortion parameters.\n",
    "- The modified co-ordinates are:\n",
    "\n",
    "$$\\begin{array}{l}\n",
    "\\hat{x}_{c}=\\gamma x_{c} \\\\\n",
    "\\hat{y}_{c}=\\gamma y_{c}\n",
    "\\end{array} \n",
    "$$\n",
    "\n",
    "- **This is applied before the focal-length multiplier and center shift are applied**: Meaning before $K$ matrix is even applied. But how do we exactly do that?\n",
    "\n",
    "    $$\\mathbf{K}=\\left[\\begin{array}{ccc}\\alpha_{x} & 0 & x_{0} \\\\0 & \\alpha_{y} & y_{0} \\\\0 & 0 & 1\\end{array}\\right] ; \\qquad      \\lambda {p} = \\mathrm{x} =K[R \\quad t] \\mathrm{X}$$\n",
    "\n",
    "    $$x_{final} = \\gamma \\left(\\frac{f_0X}{Z}+c_x \\right)\n",
    "     \\qquad \\color{red} \\bigotimes \\textbf{wrong}$$\n",
    "\n",
    "    $$x_{final} =  \\left(f_0 \\left(\\gamma\\frac{X}{Z} \\right)+c_x \\right)\n",
    "     \\qquad \\color{surd} \\checkmark \\textbf{correct}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing it up\n",
    "Let $\\pmb{P} = (X, Y, Z)^T$ - a radius-vector of a point, $\\pmb{R}$ - a rotation matrix of a camera, $\\pmb{t}$ - a translation vector of a camera, $f$ - its focal distance, $k_1, k_2$ - its distortion parameters. Then the reprojecting is done as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\pmb{Q} = \\pmb{R} \\pmb{P} + \\pmb{t} \\\\\n",
    "\\pmb{q} = -\\begin{pmatrix} Q_x / Q_z \\\\ Q_y / Q_z \\end{pmatrix} \\\\\n",
    "\\pmb{p} = f (1 + k_1 \\lVert \\pmb{q} \\rVert^2 + k_2 \\lVert \\pmb{q} \\rVert^4) \\pmb{q}\n",
    "\\end{align}\n",
    "The resulting vector $\\pmb{p}=(x, y)^T$ contains image coordinates of the original point.\n",
    "![radial_distortion_1.png](./misc/radial_distortion_1.png) \n",
    "![radial_distortion_2.png](./misc/radial_distortion_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(points, camera_params):\n",
    "    \"\"\"Convert 3-D points to 2-D by projecting onto images.\"\"\"\n",
    "    \n",
    "    proj_points = rotate(points, camera_params[:, :3])\n",
    "    proj_points += camera_params[:, 3:6]\n",
    "    proj_points = -proj_points[:, :2] / proj_points[:, 2, np.newaxis]\n",
    "    k1 = camera_params[:, 7]\n",
    "    k2 = camera_params[:, 8]\n",
    "    n = np.sum(proj_points ** 2, axis=1)\n",
    "    r = 1 + k1*n + k2*n*n\n",
    "    f = camera_params[:, 6]\n",
    "    proj_points = proj_points * (r * f)[:, np.newaxis]\n",
    "    return proj_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params, n_cameras, n_points, camera_indices, point_indices, points_2d):\n",
    "    \"\"\"Compute residuals.\n",
    "    \n",
    "    `params` contains camera parameters and 3-D coordinates.\n",
    "    \"\"\"\n",
    "    params = copy.deepcopy(params)\n",
    "    camera_params = params[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "    \n",
    "    points_3d = params[n_cameras * 9:].reshape((n_points, 3))\n",
    "    points_proj = project(points_3d[point_indices], camera_params[camera_indices])\n",
    "    return (points_proj - points_2d).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A short review on Structure from Motion\n",
    "### Residual\n",
    "In our lecture, in the residual vector, we  wrote the elements in order: 11, 12, 13.., 1N, then 21, 22.. and so on till MN. However, notice that it is not the case here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M -> camera, N -> 3D point (in our lectures, NOT in this code)\n",
    "![sfm_residual_1.png](../misc/sfm_residual_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that computing Jacobian of `fun` is cumbersome, thus we will rely on the finite difference approximation. To make this process time feasible we provide Jacobian sparsity structure (i. e. mark elements which are known to be non-zero):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sfm_jac_2.png](../misc/sfm_jac_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the matrix is sparse, we can make use of datastructures that are meant for such a usecase - https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the matrix computation has been given to you, you will have to explain this function later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices):\n",
    "    m = camera_indices.size * 2\n",
    "    n = n_cameras * 9 + n_points * 3\n",
    "            \n",
    "    A = lil_matrix((m, n), dtype=int)\n",
    "\n",
    "    camera_indices = np.sort(camera_indices)\n",
    "    point_indices = np.sort(point_indices)\n",
    "    \n",
    "    i = np.arange(camera_indices.size)\n",
    "    for s in range(9):\n",
    "        A[2 * i, camera_indices * 9 + s] = 1\n",
    "        A[2 * i + 1, camera_indices * 9 + s] = 1\n",
    "\n",
    "    for s in range(3):\n",
    "        A[2 * i, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "        A[2 * i + 1, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "            \n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THAT'S IT! Now we are ready to use inbuilt library functions!\n",
    "Now we are ready to run optimization. Let's visualize residuals evaluated with the initial parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = fun(x0, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23fafa9e20>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1125952, 333720) 89 110973\n"
     ]
    }
   ],
   "source": [
    "A = bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices)\n",
    "print(A.shape, n_cameras, n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "Scipy has existing functions for optimization that we can make use of. Write a sentence about the method that is used for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         1.8752e+07                                    3.32e+07    \n",
      "       1              3         1.4669e+07      4.08e+06       2.18e+01       1.18e+08    \n",
      "       2              5         1.4449e+07      2.20e+05       5.90e+00       1.28e+08    \n",
      "       3              6         1.4446e+07      3.31e+03       1.39e+00       1.31e+08    \n",
      "       4             12         1.4446e+07      0.00e+00       0.00e+00       1.31e+08    \n",
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 12, initial cost 1.8752e+07, final cost 1.4446e+07, first-order optimality 1.31e+08.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# So far: method='lm'\n",
    "res = least_squares(fun, x0, jac_sparsity=A, verbose=2, x_scale='jac', ftol=1e-4, method='trf',\n",
    "                    args=(n_cameras, n_points, camera_indices, point_indices, points_2d))\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = res.x\n",
    "\n",
    "new_camera_params = params[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "new_points_3d = params[n_cameras * 9:].reshape((n_points, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Optimised Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(new_points_3d)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pcd_2.png](./pcd_2.png)\n",
    "Setting `scaling='jac'` was done to automatically scale the variables and equalize their influence on the cost function (clearly the camera parameters and coordinates of the points are very different entities). This option turned out to be crucial for successfull bundle adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization took 35 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimization took {0:.0f} seconds\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot residuals at the found solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23fd485070>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEFCAYAAAAL/efAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx4klEQVR4nO3dd3wUdfoH8M+TQiI1lISSEEIJvRNBadKkqiA21DuFUxG7d+qJ5RQLEs879fxZkVPsioWz0BRQkCYEpEMgQITQeyeQ5Pn9sbPJltndmd2Z3dmd5/168SI7Mzv73WT3me98y/MlZoYQQgh7iYt0AYQQQoSfBH8hhLAhCf5CCGFDEvyFEMKGJPgLIYQNJUS6AFrVqVOHs7KyIl0MIYSIKitXrjzEzKme26Mm+GdlZSEvLy/SxRBCiKhCRH+obZdmHyGEsCEJ/kIIYUMS/IUQwoYk+AshhA1J8BdCCBuS4C+EEDZkSPAnoveI6AARrXfZVouIfiKircr/NV32PUZEBUSUT0SDjCiDEEII7Yyq+U8FMNhj23gA85g5G8A85TGIqDWAUQDaKM95k4jiDSpHxJwqLkFpmaTHFvZwvqQM367ejQMnzkW6KCJIhgR/Zl4I4IjH5uEAPlB+/gDACJftnzNzMTPvAFAAoKsR5YiUcxdK0fbpObjnk1WRLooQYXHd20vwwOercf07SyNdFBEkM9v86zLzXgBQ/k9TtqcD2OVyXJGyzQsRjSWiPCLKO3jwoIlFDc3HyxwT6GZv2BfhkggRHmuKjgMACg+fMfV13l24HX+ZusLU17CrSHT4kso21fYSZp7MzDnMnJOa6pWawjLKZDU0IUIyf/N+ZI2fgd3HzpZv+++iHZg4cxPmbz4QwZLFLjOD/34iqg8Ayv/Ov2ARgIYux2UA2GNiOQwzY+1eZI2fgV1HzK3tCGE3X6xwNAasKzpWvu25HzZGqDT2YGbw/w7ArcrPtwL41mX7KCJKIqLGALIBLDexHH79acpvePOXAk3Hfrt6NwBgw54Tbts/X7FL7XCfVu08ip2Hz+C1eVux+9hZLNl2CHuPnw38RCGEMIghWT2J6DMAfQDUIaIiAE8DyAUwjYhuA7ATwHUAwMwbiGgagI0ASgDcw8ylRpQjGIsKDmFRwSHc3adZ0OfYfvC06vbZ6/fi3IUyjOjk3qUx8s0l5T//tHE/1u1W2k9zhwVdBiFiwbiPV2HbC0MRH6fWOiyMZNRonxuZuT4zJzJzBjP/l5kPM3N/Zs5W/j/icvxEZm7KzC2YeZYRZQgHvS374z5ehQe/WA320ydw7kLErntCGGLptsMhn8P1K/L4N+tUj7nkhXmYunhHyK8lHGwzwzd/30l8maevecaXuZv26zr+162HDHldIazoxneXGXq+goOnVOcP7DtxDhO+l34Ao9gm+A96dSEe+Wqtz/1lOiZofbWySNdrnyou0XW8ENFm28FThp1r5R9H0fWFeW7bbv8guIWc1u8+jqzxM7Bq51FNxx84cc7vnXossU3wD6TJ4zNRcOCk6r5TxSX4Of8AbPKZEEK3/v9eYOr59d5tO/2sDBOdvynwcNGNe06g6wvz8MlvO4N6rWhjy+C/YMtBfLbc+w/s7Hh1On72ArLGz0Dbp+dgzPsrUHTU+CGecj0RwrzvgfO8r/8ceESf8+7ll3zrTig1ki2D/63vLcdjKp1KnjV7z2BvRueszBkQsSLn+bnlNW0zzVrnmG9z+FRxwGP15NtyTtYM9i4j2tgy+Psy/ffdYX/N4pKysL+mEGY4dKoYY6auwPIdnmm+jPX+4kIAQMGBwP0Meu4o7DZTX4K/CxmVI0To1JpHdx4+gxveWYqT5y6EtzA6ArrNYr8E/1B9amDnkIz5F7Fg2Xbvcf///ikfv+04gr7/WoCvdY6WE+awdfA/eDJwm2Egj09Xn5ASjLPnJfiL2HboVDEe+nKN13azat16Tvu3ad7limWGpHeIVtsDjE32/EDa7K5QiKBMyyvCqeISjO3dFB0bpqCsjOHZ73qquARVk4ILPyzfREPYuuZvNfKRFrFi5rp9GPHGYgBA8ydn4fs17ol72z49x+MZ+j/9RIHz/9itHV8PCf46SKopIfQrkeVNLckWwX/PMfV0yVpqDuFkl2nlQngyr82/4sSy3rA7WwT/AwZ07IZCYroQ3t5fvAMHTpobkF2/e575guzOFsHfF70Vf6vdKQhhdf5q2898vxH3fvK77nM6A7p8HUNji+BvVHOK53mMzGQISIeviD0nAkzqCrRfjfN7oiX2y3fKN1sEf6NcKHX/KB05fV7zczfvO2HIJK7SMsYv+bKgtYgtpiV2k+jvky2Cv6+/v967xt0eHcfnNeblOXb2PAa/+mvAnORaPqhvL9iG0e+vwPzN9kg+JYSnlX8Ezs2/8/AZZI2fgQ17jgc81q7sEfyDvPrnFRqToMo5c3dRwaGQm6D+OOxYL9g5O/nAyXNo+vhMrN51LKTzCmGOyDTMOzNzSr4u32wR/F3NXr+3/Od3f93u99gT56y/AtfSbYdRWsZ4b5GsbSqij56Uy56kwzc0Ngn+FR+wcR+vKv95zgb/TSeBKulaP3taLyJapq37KpM0bYpoJnNcws8WwT/Sn6vX5m01/Jzkcenx9eU5XVwS1IgKIYxgtdq51n46O7BF8A+WGQmk/F6Igng5f3MPzl0oRdeJc9F+wo/6TyyEAV6ane93f7gvDr/t8E43bVe2CP7BhvCAdwwWqtV4FrXgwCm0/MdsnJY00SKCZm/Y53d/aHfl7l/AC6Vl2B8ghcOBE5Gd7W8ltgj+0e7F2ZvLsyJ6fld8XX/y9500tUxCGCmYa4DnXcOT09ej2wvzcOa89QdqWIHpwZ+IColoHRGtJqI8ZVstIvqJiLYq/9c0uxzBCNQJ5dnurumcfvb95mPt07d+2Yb7PvOYBu/50l5rD0gHmogeRvTL/aQM79y63/fM+xUGDd+OBeGq+fdl5o7MnKM8Hg9gHjNnA5inPDZNsB+scIfPB79Yrfs5cUr1xzXY7z1+Fvd+qj9nihDR6sz5kvIZ96PfX+7zuPz9ckfsFKlmn+EAPlB+/gDACDNfLNhhZAGHekagzd+zTM4yuG73XDhDiFh3zycVQ7jPaOjn2rL/pO2/J+EI/gzgRyJaSURjlW11mXkvACj/p6k9kYjGElEeEeUdPHgwDEV1d6HM97Cwdl4rEYVOz0WKAOw6cgY7Dp1Wnmt4cUQAfxw+jeZPzDI8wZ8dhfrx/Tm/Ij4Ul5Th2R82qh7nrK8NfGWhd1OqzYQj+Pdg5s4AhgC4h4h6a30iM09m5hxmzklNTQ26AMF+sN5fVOhz38ni4DqVQpnMMm3FLhw/WzFmv9c/f8ZLcxxD6VybfYLpixD6fb9mD86XluGbVUWRLkrUOqlMgAzme5E7czNKSmXcfrBMD/7MvEf5/wCA6QC6AthPRPUBQPnfMmkqTxeX4O5PVuLgyWKcD/DBUguxzIzjZ4KbVBXo4//3r9eW5yxRM2nWJnyzqkhXc9Te42dxKsgLmRCh2qcMzQwmB8/ywiOYs2E/9h5XX6lP+Gdq8CeiKkRUzfkzgIEA1gP4DsCtymG3AvjWzHLoqVS8++t2zFy3DxdPnBvUa32wpBAdnv2xPAGbHqE03TAD7yzYjr9NW6PreZdOml++0LbQR5raIq+UGU9OX6/5eFmQqYLZNf+6ABYR0RoAywHMYObZAHIBXE5EWwFcrjw2jZ5hj6/O1Z6KQe2DNHeT4yZm/e4TPsqiTVkZ49gZ3+sFGPkhLjjg3WZ99nwphr32K9ZIttCAtDazPfP9Bkyaucnk0thLXuERzNtsfMOBsx/n2JnzGPHGYuw6csbw14g0U4M/M29n5g7KvzbMPFHZfpiZ+zNztvJ/zAy+XVTguH2959NVAY707+WftqDjsz/h8Cn1GYm/73TPae56UTHiwrC26Bg27DmBiTP8B6vjZy9gjsoszj3HzpannY52b/xcoDoyRMuF/ONlf2DhFkdn5PuLC/HOwu2a8tELbT5c+oeu47V+M3JnbQYAzFy3D6t3HcObvxToLJn12WOGr4Vuz7/M09Y56JwW72u1sE9+2+n2+KxJaRyWFx5BcUnFub9dvRuvz9+KC0p/yL2frsKdH63EHo+Fbrrnzg+66Syc1u8+jh2HTuPM+RIMfGUB7v5kpdcxL83Jx32f/Y6/f7UGeYVH8KPHxc7ftfbJ/63HLe+5jzu/5q0lhqzqJvTz/FvN3bgfOw/7rtU7j/9s+S6s/CNm6qgAgIRIFyAczIr9O4O4FXx8+jpNx6k1xfjjvOMAgFI/Q1S1cv2dTfl1B+7p2wwA8MDnqwE4OuqeH9Gu/Ha4uKQMSwoOYcv+k+iZHfzIrHC74v8WAQBuyGmILftPYYuf2aHT8oowTbl4F+YO89nmv+/4OZw5XwLXVPWeI4K+WbUbN3XLDK3wBnOOuAl3u/iE7zaE9fVc3f6hY3W9wtxhqvvXFh0r//mrlbvRpVGtcBQrLGwR/M1ixu17SWkZEuJDuyF7YebmgMfsOXYWCfEVX3Jm9vmld95VuNZWP162E5UruX98bpryWzDFLbd61zGkVktCespFup534OQ5FB09i86ZFVlCur0wF4Pb1MMzw9t6HZ+/7ySapVVFfFzF+93rkhBMy9/AMaPU0azl+Vu7ZNI8r+O/WbXb7fHj09dZLvh3eOZHnDhXgo9u64peYbyAT11SGLbX8uWLFe530udLylBaxvhs+a7ybZ8t34lJI9uFu2imsUWzj1mjMj5bvjPwQTqdPFcSllW5uufOR9eJFUFqs0ciuDKVFZYueAx9nbxwu6F3VSPeWIweufN1P2/Iq79i5JtL3LbtP1GMDzzag53rug56dSH+47HGwo5DFTX+52dsCrjCVOun5pSfX8ucD3/nW1t0DFnjZ6Do6Bks237YtCa8QJyLDr00Jx8lpWXYGoOpEHx1zj/6tfsd+YItB2N+gRlbBP81Lrdu0cDX7EQzeQYn11q8c7SU6wQzpz+U9tK+//rFtLLlFR7xu0bxYR/9Ip5W7qxos/XsMN91pKLPYuqSQny4tFBz+Q5o6Nheut13Hnln7fLT33Zi1ORl+PvXazW/tln+8e0GXP7KwvIZ5CL22CL4T8vbFfggizKj7hGoZvmdx8gWZketv+eLP+t+ra9Xhj779dq3l+qai+Arpe+SgooAfKG0zO8F66iOiXrBtpB7/h0+Uu4k8vepDxPWY8+xs3hnwbaga6/Ou9rPTbi7jSgC/vf77sDHBbC26JhXhangwClMUdYFP3O+BN+sKrL03YMtgv8ffnrzrcaz2T2UBa5dlZUxtuw/iazxM9Dqqdle+52f0Td/KcD9HjlPjp45j5veXRbU6z70pfeks8kLt2HVTvOGO3p2lt/+QR6yxs/Aly4XomXbj/it1Z5Qucsx2o8bHaOGnDNUnc1He4/7X5BEi9s+yMOkWZtRdDS02a/FMbjs4az1ezUd59k0CABZ42dgybZDuOr1xXjLY/jngJcX4PkZm3CquATPfr8Rf5u2xi1N+4ET55A7a7Nqk2okSIevxRlVcRg1eRmWB8hl/tXKIvxTZdk9106vUJ27UFreIe1rhIU/367ejfg4whXtG6ie+4HPf8fwjulu2/2lxPBl6pJCTLiqjaZjXTvK527U/1qHPOZyOPPdBOvHDfuwaa/j7qHMwjXPSNE6Ke//5quP7X/kS0ez3Ma96ndo36/Zgz3KBdz1LrTrC44+trRqSfhLz8aay2uWmA/+N08JrsYaKSUetYIf1hqTdjZQ4D90uhgPq9TSjeYZ6PSYuW5v+VBTteDfbsIcXChlzNmgPwD7kjV+hq7jnUMHtXAGZq3x+cCJc7hk0jx8c3cPdGyY4vO4sR95z1UwyoET51A1OXrDBiH0VOy7lTktvi4ij31T0XmsdsyzP2y0RPCP+WafxQXRtWBzXqF7c4jnKByzjHl/RVheJxR3f+J/1vSFUmNruZ6TuXz5aaO24zydOOuoFWr9Gy/edghlDExd7D0a7Mz5EjR5bAbuVZlZfuT0eSzz0eG8rui42yQ+wL0Pw7NfousL89D6KePTmYfTrPXB/b08aWoSs3AqoZgP/tFm3Mfutbb5JuQtiSQtAVpvbdufUGZlaq1Bn7tQhke/0j9C51RxCXYcOq27X+d/qz075BmTF25HGQM/rHVvzyYQbnhnKUZNdtwB7z9xrjxf064jZ3Dl64vQ4snZbik61hQdL//5iygeLKHG11KpwdCyjoOFY78EfxFeH7mMvV+/+7ifIx2+Xe1/ZEagzrNr3lqqrWAhCiZIvjQn3+eII2ftvrikFEu2+U93PPr9FT4TEu46egZbXTrAu70wD8OVkVOuqUPuNLGpKFbtOHQa/5qTj5fmbPYaOuxpuwUX/InexjsRlU6eqxhFc8X/LcLTV7bGzd0aoVKCez2kuKQUSQnxAWtqTR6faUo5I23C9xtxWYs0vPvrdnz62078cF9Pt/27j53F58t3omW96liwxfcqd54jt1xJV3DoXv/Z0Sn8xs/bVPc7BwNsseCEOQn+Imwe/nINvvIY9//M9xtx5PR5jO6e5ba96OhZNE2t6vO22V86ikjx1a4erLd+KSjPJbR61zFUTar4umqdCe06Ac61fNNW7ELDWpU1naPPSz9j+t09kJwYr+l4UcG53Oq4j0PL8msGsvIkBFc5OTmcl6d9JIWTke3HIjg7Jg0FEen6W9zeszE6ZdbEgi0HygOgqyqV4vHEsNaaE+XFgldv6IgHv1gdsdcf1r4+ZqzVNkZeOHTOTMGqnce8tmsZ5rzn2FmkVE70yqGlFxGtZOYcz+1S8xemm7fpAAa0rqvrOVMW7QDgO8fR6fOltgr8AFTXFAgnCfz6qQV+ANi87wRa1qvu83nMjO6589GlUU18fVd3U8omHb7CdHrGvgvfzFixSkTG4Fd/9bv/nYWONBFmLvwjNX8hhIiAM+dLvJp0jp4+jwe+WF2++puZpOYvhBARkL/vJE55pAO/9u0lYQn8gNT8RZh4rgUghN1draxB4dr5u+1g+FJoS81fhMXN74a2ypcQser5HzZi6/6TKAlzBUlq/iIsAiWWE8KupizaoYxuCy+p+QshhIXpWchIDwn+QghhYf6WMA2FBH8hhLChiAV/IhpMRPlEVEBE4yNVDiGEsKOIBH8iigfwBoAhAFoDuJGIWkeiLEIIYXWni0Nb2lNNpGr+XQEUMPN2Zj4P4HMAwyNUFiGEsLTzWlYN0ylSwT8dgOvqF0XKNjdENJaI8ogo7+DB8Mx6E0IIq4mLMz59eaSCv9o78cotzcyTmTmHmXNSU1PDUCwhhLCHSAX/IgANXR5nAIhsvlohhLAo14V8jBKp4L8CQDYRNSaiSgBGAfguQmURQghLizeh2Sci6R2YuYSI7gUwB0A8gPeYeUMkyiKEEHYUsdw+zDwTQGyuvi2EEBYnM3yFEMKGJPgLIYQFXNWhger2/OcHm/J6EvxF2FSuFB/pIghhSU8Oa4VXb+ioui8pwZzvjeTzF2FzR68m+M+8rZEuhhCW0Kh2ZYzpnoXRPRr7PMbXBcEIUvMXYTGsfX3c2DVT8/GPDm6J+jWSTSyREJHz9V3dseCRvn4DPwA0S6tqWhkk+AvTFeYOwxs3dYbnUOXuTWvjv7fmYOEjfb2ec1efpligsh0AmtSpYkYxLW38kJaq29V+d8JaHuif7bWtS6OaESiJOwn+ImxqVamEmpUTyx8PbVcf/VvVRWbtyprP0TkzBfMf7oPF4/vhiaGtzCimJWydOAT9W6ahd3NHWpNxlzV127/gkT4ozB2GzNqVkVotKRJFFAG0rl8dANCxYQom/7mLpudU85jJy15Jb4wjwV+ETUJ8HH5/amD5Yz3NQL2y6wAA3rzZ8SVKT7kId/RuYmwBLSQxPg7/HX0x/ntrDlY/dbnX/ka1K+5+tM79bFjrIoNKJwIpzB2GtOoVF2UibX+lH+7viZev72BWsdxI8BcRcX1OhtuU9edGtPV5bBwBH93WDYW5w1BPQz/A/f2aGVJGK0iMj0NK5UoAHCNCptySg0WPBtfUE6cxAAXSt4UkWdTL9e6slXJHoKZR7SoY2TkDGTUdF2qD/mSqJPiLsCvMHYZ/Xuteu/nzJY0MO/9N3Yw7l5Xc3qsJBrSui4ya2pvJXBkVR94f09WgM0WvH+7r6fbYNUj/+zrHZ7tBiiOAV0tOQMeGKeX7WUNbzrQ7L8W9fZuhTQPfF4pQSfAXlufvlvmuPk29ttWrkYyPbgtvgGpZr1pYX8+V1tqh6+8xTfoJQtI2vQa+vuvS8sd1qibhpWvbY2SndFzTJQMA8NQVrfH6TZ2Qk1ULAHCn0kx5SZPaAc/fIOUiPDyohebmomBI8BdRrV/LNNXtdauHd5ioM/jXrlIprK+rh2sc+XJcReDKqHkR3h9zcQRKFN26NKrl9vi6nIZ42WVcfnJiPK5oXzFrt2V9x2dES9NlOMgkL2E5hbnD3B77q/tcnFXLz97wmXh1O/RunoqRnTOQNX5GWF+bNDbouB7VqHYVvH5TJ9z76e8AgL4t1C+iQpve2YH7QUZ0TEdCXByGtK0XhhIFJjV/IQxQJSkBIztnROS1tbYMODuOndqnp+h6vnCYfnd3r22TRrYL+DwiwpUdGiAh3hph1xqlEELRJNV7ApdVgpNVyuFJa7EeH+o+UYy9V04VLn64r6fqyJxOmd4TtColRF8ojb4Si5iV9+QAt1EU0RqcvnJpT9eqe9PAnYChquJjKUC1ZqNcDTVZK/rb5c1VZ9QGo216DVyrdN6O6ZGF90bn4OGBzQ05txVIm7+wjDpV1UegaG3TNhsBmi5HORbphwgkOdGRLTJLJV3GqK6ZGNU1M+z9F6HKyaqJLo1q4sDJYlRLTsDkhdsDPqdb41r4bceRgMf1a1kX/VrWNaKYliA1fxGTrHG5CA+twwE9L6J1qyfj/dEX4/WbOplRLE0aG5ynKbNWZSQlxGPSyHZeKTF8efPmzoaWIVpI8Leosb2b4G+Xx84tZjDMzGtiNZHqT+jbMg3VkxMDHxiiWy71nnj33Ii2+KvBn/EGNSpSWGj9lZqxOHo0kGYfi3p8aCucKi7B4oJDmm5J9cpOq4qtB04Zfl5TWOS7SUT2uiIFYWi7epi5bh8Ax9yHzftOAgAmXNkGIzqlIyGOcPzsBdStnozmdath5rq9Ib1e+4waePn6Dhjw8kIAQJyPQJ4YT7hQ6v23a5paxTLNiuEmNX8LGNu7CdY/MwjdGru3FVdNSsAXd15anh3QKJ/c3g3VLzK/tie0C0cACsfdxQ0XZ5Z/Xp+5qk359rg4QufMmmifkYJe2aloXtcx4SnUa+mlTWujWVo1TLy6LeY9dJnbvmrJFXXbTg3VUyhfl9PQMpWLcJPgbwGPD22FqkkJmHxLDkZd3BA9m9Vx259ZK7hcLr708Di/1Vnlu2mVcnhyBvXn/STHM5q/5GTO8vgaXeTKqBFdN3drhKap7gufuI6nr11Vfeb1nb2b+L0oxpPzf6v+9YMnwT/CXGf71bgoEbnXtMfHt3dzOyalsj1r6XZqYQkltjifG2iWqZHh65UbfKcd7pSZAsDxeQ6kzM/feHCbwDNhQ71jIvJ/hlFdMzG6exYeGGDM8FErkeAfRp5f8Eub1MZbfwq8yMOdGkctxCqrVLqsUg5ftNaib+qmfR0FvRrUSMZTV7TBzPt7oaGGO1YtGS79qVtdf4K65ET3sOdvtFRyYjwmXNUG1cLQKR5uEvzDKNjYkWDT0QjROskr3PTUfgtzh+GFq0OfwKU2RLNb41rIrlsNlRLi0FpnKuKW9aphxv093ZY3dI3JnmsYXNM5A2/c1Bm3Xpql6fyPDGqBtumOMnleb+z57TIx+BPRBCLaTUSrlX9DXfY9RkQFRJRPRIPMKoPVVPVoAzW6LX/i1eFr8w2nYG7tzailW31USKBKtJG/k6SEeK9tjXQsx+k0uG093Ng1Ex/f3g1tGtTA8I4NVI/zXMMgjoBh7ev7HN3jqUlqVXw1zjsnD+Co3duxfmV2zf8VZu6o/JsJAETUGsAoAG0ADAbwJhF5f5Ji0F193FeYapNu7CiemzUsYmLU1HdhHVZvjvLHOSHLObvbdVEfs96X5zUyPo6wfdIw1WNjWSSafYYD+JyZi5l5B4ACADGzNNB39/bwuS/Y5E/OJeAe1NDpVD9ArvA0lTZS10XVa1qoc9leHb7hiODGvsY7f+6CB/pnl38ur+ygXmvXg4iw/plBWP+M/waBkH5dGj5XOyYNDXxQlDM7+N9LRGuJ6D0icjbmpQPY5XJMkbLNCxGNJaI8Iso7ePCgyUU1RvuMFMPPmZwYj8LcYXhwQODZkM6l43xxXVzCaf5DfdweezZPRZplarZWKYcHZ23Z13BGswxqUw9/vbw5HhzQHIW5w9BLQ057LaomJaBqUoLhzWxaP0d1qiaF6WIcWSEFfyKaS0TrVf4NB/AWgKYAOgLYC+DfzqepnEr1WszMk5k5h5lzUlOjf9FoK3yc1IbfuU6GAYB1EwaimgUuAMmJ8UiMJ/zjitaRLopfDQxYmcn1s+E6OUqL23s1QWHusJgckWKkhDhHuBvZOR1LxvfDT3/trXqcWr7+WBTSN5yZB2g5jojeBfCD8rAIQEOX3RkA9oRSjmg1SMM4Zr3qBbF8oWsth5XHVmhxiY8jbJ2o/fb7/v7ZqO5xIWuaWgXbDp42pDy+Lt5G/65u7Z5l8Bkdoq0yW7mS767AYBbOiY8jrJswEJUrJajm8+nbIhU/5x/UNEQ1FphWvSOi+szsTNxxNYD1ys/fAfiUiF4G0ABANoDlZpXDiga0SsOUW81ZM7VlvWqYoSNfSu7IdqpfhLIobHBXS4QXLe8iHIHZ8w4vHB4f2hJb9weXQ+rJK1rjy5VFXtvTUy7StAi6Gn93R2//uQtOnisJ6rzRyMw2/38S0ToiWgugL4C/AgAzbwAwDcBGALMB3MPMpSaWw1b0BpFmae5T4p15WaIw9nswPpr6+t2qpTGY75Fnxunevs1Ut4dDWrXwLxw+tndTvHSd79nA/ng2UT43XF9zmF5JCfE+15SIRaYFf2b+MzO3Y+b2zHyVy10AmHkiMzdl5hbMPMusMliNc2KM51qqVuAcJRTO/DBW17WxtkVZ1IJ/E488M05Xd05Hh4wabttu7JqJ3JHt9RcwAtronLxlpD7KIvPR1nxlVTLDN0RaOyNrVk5EnxapmHBla0zQ2aGnxy0a24uHtasPoGLyjPP7lKSs7iSza4EP/9IVSx/rV/7Y1+iTRJ0zhDybLCaNbId6BnQah8Ont18SsdeO/rtRa5HgH6KGNf0PrXS6on0DEBFG92hs6lDK6smJaFmvWsDjxvTIwqZnB/sMOvJFc4w2qhugqeTOy5rgPzfqXAnLxJqrM6nav4JsavGnW+NaqGGBeSBS8zeGBP8AfCWOcqZmyK5bDff189+O++I17Uyt7QeitooSEeEildEUzkRbsRr7jQ4cjw1phfQAcytcmX1R/eyOS5D35IDyhcf1eCjAqlqRDrq1lHkMrrOARfAk+Afg68v6yg0d0Su7DhrWvAgPDWzh9xzVkxNNXyrOcw0AVwRg3kOXYcb9PX0f4/nNNihIabkLCZeezepgzdMDdT3H9ddiVPAzM0dQcmLwnZb9W/lfnDzSuY2qJiWgMHcYxva2d5Zbo0jwD8KapwaiS6Oa+Oi2bm4LRnjSko/cDM50EK6aplZFmwY1VI5W948rjZlY5bnARiQlJ8ajenIi/tKjcUTLUbuK9Tr8Af/9PNWSEnC/5IXyoueuz2oiP43TohLiCCVl6l8Hve2e4WhCcS3pa6M6odNzP+l6fnrNi7D72FlUUi5mTVVS9gYlQpXFxnWqYETHBrijdxMMe20RgIqmOucQwqpJCThV7H9ct+sdkTFvhTGmRxYmztzkteff13VA/RRrdfy+NzoHu4+dk6YWH+b+7TJcKCuLdDGCIjV/H8b2bhLS87s0qlneTBCOzlPX16jpUbPU8vLv/KkL3rq5M9KCmCHsT6QaCuLjCK+O6uR2tzN+SEsAjjTCgPsqalpk1zWmCcvX3eI1XTLQvalxS2xOHXMxrs/R3vav9jnt17KuBH4/LqrkuJuMRhL8TbBj0lB8Ne5SUzrI/LXbh6JmlUoYogz/NJKVEmQ5s6q2qFfNkSgvQAenp6ljLsYnHktsBuuGnIaBDwpRnxZp+Oe1xo/6EbFBgr9Ob97cOeAxROSRL8e4qr+edvtQtFUmIt3Xr1l5H8JtPfW3lVu1fRtwtNfW8lG+fi3TvLalVK6EHn461j3d0cv799WkjqMP5MVro2NSl4hdEvx9UKuwrpswEEN11I7DOTrC6Kal6smJKMwdhocGtihPE+063T5NpVNZzd8H+x8JFWm+/kJaZrIGypXjmeJ4RMcGmleeEsJsEvx10Jsy1zmBKhKpdr8ad6lhbbVJSnOJs5Y8slM6vr5LW9rbZJXl/qwkOVG9fP5C9Bs3Bb77U/OcpM4QFiKjfXy4PqchPlu+CyM6NsC7v+4IePy39/TwakL4++AWaJ9RA72zjevE0yonqxY27DkBIPS7gtdGdcLHy/7Azd0ykVHTkVHRV9CMNo8OaYn7P/u9/HGLutWQv/+k3+f0aeGo0fvK3+OL1fPty6xue7FVzX/G/T1RmKu+VmdyovuvolHtKlj1j8u9Fo72pUPDFK884EkJ8RjeMT1inZ5GvWy9Gsl4eFALEBH6tEjzCvyuv1PPpGXhaOa487ImSIwP7nV6Z9dB5UrxqnMjfKmSlICpYy7G1NH+03KrLZwj9Pn0jm6YcktOpIsRk2I++K95aiDWThiIwtxh5Z2lV3msNVqrSiV0bJgSgdIZ53aVzsVwcgbPvwTRKRyqx4a08rvoy5geWUjwcRFKqVwJG58djIuzaqru96VPizSvIbWeOjRMiarAZcVkft2b1sGA1v5nHovgxHzwr1E50Wsc7ms3dnIbMvnjX3v77Jy10EhFn3JHtgs4Nd9sf+rm6F+oa/A8ASM8fWUbFLzgf0WwO3o1QVJCHLo10ZbGWatoDFzt0sMzokxElm3b/F2HTEbbAg6ju2dh6pLCSBcDo7tn4XIluN3brxkuaVIL3VzSFVttIXh/OmXWRP7zQ/CfuVvD9prLn+gPK00OdTbnWfECLowXPd9OE7h27r14TXu8OncLvvl9t+qxVprlOOGqNuXBv1pyQnkA9pSd5piR2sGkJi3XTKXxceQW+AFg9oO9THndcFv55ABTEvNFYmUtf5rXrYZXbuiAfi2j725F6Gfr4D/7wV7lIxwya1fGyzd09Bn8rca52PS6CYN8HnNp09pY+EhfNKwV3uRTr93YCXM27NPcWW51taPszjAUV3fSnwpaRCdbB3/HTFzv7ZHKxqnHW3/qgmNnLgQ8LrN2+APwVR0aeHWq21mfFqloVT9yyx8KocbWwV9NwcQhiIuCXt7kxHjUqxEbY+2tpH+rNLwydwsub21cBWDqmK6GnUsIo8T8aB+9EuLj3MamD25bDw1qJGN0j6zIFUqETdv0GijMHYZ2GTLiRcQ2qfkHkFYtGUse6x/pYgghhKGk5i9EjIvm1aaEeaTmL0SM++bu7li/+3ikiyEsRoK/EDGubvVkmbglvITU7ENE1xHRBiIqI6Icj32PEVEBEeUT0SCX7V2IaJ2y7zWy0lJPQghhE6G2+a8HMBLAQteNRNQawCgAbQAMBvAmETnHJb4FYCyAbOXf4BDLIIQQQqeQgj8zb2LmfJVdwwF8zszFzLwDQAGArkRUH0B1Zl7KzAzgQwAjQimDEEII/cwa7ZMOYJfL4yJlW7rys+d2VUQ0lojyiCjv4MGDphRUCCHsKGCHLxHNBaA23fEJZv7W19NUtrGf7aqYeTKAyQCQk5NjvWTjQggRpQIGf2YeEMR5iwA0dHmcAWCPsj1DZbsQQogwMqvZ5zsAo4goiYgaw9Gxu5yZ9wI4SUSXKKN8bgHg6+5BCCGESUId6nk1ERUBuBTADCKaAwDMvAHANAAbAcwGcA8zlypPuwvAFDg6gbcBmBVKGYQQQugX0iQvZp4OYLqPfRMBTFTZngegbSivK4QQIjSS20cIIWxIgr8QQtiQBH8hhLAhCf5CCGFDEvyFEMKGJPgLIYQNSfAXQggbkuAvhBA2JMFfCCFsSIK/EELYkAR/IYSwIQn+QghhQxL8hRDChiT4CyGEDUnwF0IIG5LgL4QQNiTBXwghbEiCvxBC2JAEfyGEsCEJ/kIIYUMS/IUQwoYk+AshhA1J8BdCCBuS4C+EEDYkwV8IIWwopOBPRNcR0QYiKiOiHJftWUR0lohWK//edtnXhYjWEVEBEb1GRBRKGYQQQugXas1/PYCRABaq7NvGzB2Vf+Nctr8FYCyAbOXf4BDLIIQQQqeQgj8zb2LmfK3HE1F9ANWZeSkzM4APAYwIpQxCCCH0M7PNvzER/U5EC4iol7ItHUCRyzFFyjYhhBBhlBDoACKaC6Ceyq4nmPlbH0/bCyCTmQ8TURcA/yOiNgDU2vfZz2uPhaOJCJmZmYGKKoQQQqOAwZ+ZB+g9KTMXAyhWfl5JRNsANIejpp/hcmgGgD1+zjMZwGQAyMnJ8XmREEIIoY8pzT5ElEpE8crPTeDo2N3OzHsBnCSiS5RRPrcA8HX3IIQQwiShDvW8moiKAFwKYAYRzVF29QawlojWAPgKwDhmPqLsuwvAFAAFALYBmBVKGYQQQugXsNnHH2aeDmC6yvavAXzt4zl5ANqG8rpCCCFCIzN8hRDChiT4CyGEDUnwF0IIG5LgL4QQNiTBXwghbEiCvxBC2JAEfyGEsCEJ/kIIYUMS/IUQwoYk+AshhA1J8BdCCBuS4C+EEDYkwV8IIWxIgr8QQtiQBH8hhLAhCf5CCGFDEvyFEMKGJPgLIYQNSfAXQggbkuAvhBA2JMFfCCFsKCHSBRBCCLP8Z1RH1KmaFOliWJIEfyFEzBreMT3SRbAsafYRQggbkuAvhBA2JMFfCCFsKKTgT0QvEdFmIlpLRNOJKMVl32NEVEBE+UQ0yGV7FyJap+x7jYgolDIIIYTQL9Sa/08A2jJzewBbADwGAETUGsAoAG0ADAbwJhHFK895C8BYANnKv8EhlkEIIYROIQV/Zv6RmUuUh8sAZCg/DwfwOTMXM/MOAAUAuhJRfQDVmXkpMzOADwGMCKUMQggh9DOyzf8vAGYpP6cD2OWyr0jZlq787LldFRGNJaI8Iso7ePCggUUVQgh7CzjOn4jmAqinsusJZv5WOeYJACUAPnE+TeV49rNdFTNPBjAZAHJycnweJ4QQQp+AwZ+ZB/jbT0S3ArgCQH+lKQdw1OgbuhyWAWCPsj1DZXtAK1euPEREf2g5VkUdAIeCfK6VyfuKLvK+okusvK9GahtDmuFLRIMBPArgMmY+47LrOwCfEtHLABrA0bG7nJlLiegkEV0C4DcAtwD4Py2vxcypIZQzj5lzgn2+Vcn7ii7yvqJLrL4vp1DTO7wOIAnAT8qIzWXMPI6ZNxDRNAAb4WgOuoeZS5Xn3AVgKoCL4OgjmOV1ViGEEKYKKfgzczM/+yYCmKiyPQ9A21BeVwghRGjsMsN3cqQLYBJ5X9FF3ld0idX3BQCgij5aIYQQdmGXmr8QQggXEvyFEMKGYir4E9FgJZFcARGNV9lPSjK5AiUZXedIlFMvDe/rZuX9rCWiJUTUIRLl1CvQ+3I57mIiKiWia8NZvmBpeV9E1IeIVhPRBiJaEO4yBkPD57AGEX1PRGuU9zUmEuXUg4jeI6IDRLTex/6ojBmaMHNM/AMQD2AbgCYAKgFYA6C1xzFD4RhaSgAuAfBbpMtt0PvqDqCm8vOQWHlfLsfNBzATwLWRLrdBf68UOIZBZyqP0yJdboPe1+MAXlR+TgVwBEClSJc9wPvqDaAzgPU+9kddzND6L5Zq/l0BFDDzdmY+D+BzOBLMuRoO4EN2WAYgRUk2Z2UB3xczL2Hmo8pD1wR7Vqbl7wUA9wH4GsCBcBYuBFre100AvmHmnQDAzNHw3rS8LwZQTUnTXhWO4F8CC2PmhXCU05dojBmaxFLw95VMTu8xVqO3zLchOibOBXxfRJQO4GoAb4exXKHS8vdqDqAmEf1CRCuJ6JawlS54Wt7X6wBawZGyZR2AB5i5LDzFM000xgxNYmkBdy1J43QllrMIzWUmor5wBP+eppbIGFre16sAHmVHWhDzS2QMLe8rAUAXAP3hmOm+lIiWMfMWswsXAi3vaxCA1QD6AWgKx8z/X5n5hMllM1M0xgxNYin4+0omp/cYq9FUZiJqD2AKgCHMfDhMZQuFlveVA+BzJfDXATCUiEqY+X9hKWFwtH4ODzHzaQCniWghgA5wLIhkVVre1xgAuexoLC8goh0AWgJYHp4imiIaY4YmsdTsswJANhE1JqJKcKwk9p3HMd8BuEXpwb8EwHFm3hvuguoU8H0RUSaAbwD82eK1R1cB3xczN2bmLGbOAvAVgLstHvgBbZ/DbwH0IqIEIqoMoBuATWEup15a3tdOOO5mQER1AbQAsD2spTReNMYMTWKm5s/MJUR0L4A5cIxMeI8dCebGKfvfhmPEyFA4VhY7A0dNxdI0vq+nANSGY7lMAChhi2cj1Pi+oo6W98XMm4hoNoC1AMoATGFm1aGGVqHx7/UcgKlEtA6O5pJHmdnSKZGJ6DMAfQDUIaIiAE8DSASiN2ZoJekdhBDChmKp2UcIIYRGEvyFEMKGJPgLIYQNSfAXQggbkuAvhBAWFCjpnMrx1xPRRiWp3qcBj5fRPkIIYT1E1BvAKThyC/ld+paIsgFMA9CPmY8SUVqgnFFS8xdCCAtSSzpHRE2JaLaSE+pXImqp7LoDwBvOBI9akgVK8BdCiOgxGcB9zNwFwMMA3lS2NwfQnIgWE9EyIhoc6EQxM8NXCCFiGRFVhWPtji9dEh0mKf8nAMiGY7ZyBoBfiagtMx/zdT4J/kIIER3iABxj5o4q+4oALGPmCwB2EFE+HBeDFf5OJoQQwuKU1Ng7iOg6oHyJSeeSrf8D0FfZXgeOZiC/SfUk+AshhAUpSeeWAmhBREVEdBuAmwHcRkRrAGxAxWpqcwAcJqKNAH4G8Eig1O4y1FMIIWxIav5CCGFDEvyFEMKGJPgLIYQNSfAXQggbkuAvhBA2JMFfCCFsSIK/EELY0P8Dds5tClcv8nMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see much better picture of residuals now, with the mean being very close to zero. There are some spikes left. It can be explained by outliers in the data, or, possibly, the algorithm found a local minimum (very good one though) or didn't converged enough. Note that the algorithm worked with Jacobian finite difference aproximate, which can potentially block the progress near the minimum because of insufficient accuracy (but again, computing exact Jacobian for this problem is quite difficult)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2- Part B: Submission details -\n",
    "You are supposed to gain understanding by playing around with the code above and submit your answers to questions asked below. You shouldn't submit this whole notebook, just copy the following cells (starting next cell up until the end of this notebook) and paste it at the end of your Project 2 notebook (already shared on GitHub classrooms, [link](https://github.com/AryanSakaria/Project_2/blob/main/Project_2.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "## 1. SfM pipeline (`6 mark`)\n",
    "\n",
    "To get the context of below questions, take a look at the code above: The same questions have been asked at different places above as comments in the code.\n",
    "\n",
    "1. `0.5 mark` **Basics** - How do we know this (`camera_ind`) information in practical setting? In other words, how do we know observations in `points_2d` belong to which camera. Explain. \n",
    "    - Ans-1 - Basics:\n",
    "        When a camera takes a picture, it often stores the timestamp of the image. based on these timestamps, we can assign `camera_ind` to each of the images by iteratinfg over them. \n",
    "        The backend structure of the motion pipeline contains Bundle adjustment. The working of the frontend part can be demonstrated through the following steps -\n",
    "        - From various unknown locations, multiple images of the same object are captured with (usually) the same camera.\n",
    "        - SIFT / ORB is applied on the first 2 consecutive images to obtain common feature points in these images. \n",
    "        - Essential matrix and Fundamental matrix are obtained using 8 point algorithm. These matrices are then decomposed into rotation matrix(R) and translation matrix(T) between the 2 images.\n",
    "        - Using the same scale during the whole process, we triangulate from image points to 3D world.\n",
    "        - The information about the source of the points being back-projected is stored in camera_ind. And this information is known to us.\n",
    "        - PnP is applied over the correspondences between the third image and the reconstructed world to obtain the rotation matrix and translation matrix of the third image on the same scale.\n",
    "        - This process is repeated for all the images.\n",
    "        Thus, the correspondence between the points_2d and the camera to which these points belong are known since these points are chosen after applying SIFT/ORB or some other feature detection algorithm on the image from that camera.\n",
    "\n",
    "    \n",
    "2. `0.5 mark` **Basics** - How do we know this (`point_ind`) information in practical setting?  In other words, how do we know observations in `points_2d` belong to which 3D point. Explain.\n",
    "    - Ans-2 - Basics: \n",
    "        - In the frontend pipeline, once the F, E, R and t matrices are estimated, the initial estimates of the 3D points are generated by triangulating and back-projecting 2D points from the images. \n",
    "        - So, because of the nature of the method used, we can easily find out the correspondence between the 3D points and the 2D points from which they were generated. For representing the correspondence, we can use indices for each of the 2D points and label the corresponding 3D points with the same index.\n",
    "\n",
    "3. `0.5 mark` **Transformations** - `rotate()` function: Why do we use the rodriquez formula? How is this representation different from the standard 3x3 Rotation matrix, why do we use this instead?\n",
    "    - Ans-3 - Transformations: \n",
    "    If v is a vector in ℝ3 and k is a unit vector describing an axis of rotation about which v rotates by an angle θ according to the right hand rule, the Rodrigues formula for the rotated vector $v_{rot}$ is\n",
    "$$\n",
    " {\\mathbf {v} _{\\mathrm {rot} }=\\mathbf {v} \\cos \\theta +(\\mathbf {k} \\times \\mathbf {v} )\\sin \\theta +\\mathbf {k} ~(\\mathbf {k} \\cdot \\mathbf {v} )(1-\\cos \\theta )}\n",
    "$$\n",
    "Using axis angle for rotation instead of rotation matrix, number of parameters that we need to estimate get reduced. The total number of parameters is just 3. By extension, this formula can be used to transform all three basis vectors to compute a rotation matrix in SO(3), the group of all rotation matrices, from an axis–angle representation.\n",
    "\n",
    "    \n",
    "4. `0.5 mark` **Transformations** - `project()` function: In the `project()` function, would it make any difference if I do translate first, then rotate? Why/why not?\n",
    "    - Ans-4 - Transformations: \n",
    "        - `M` denotes the number of images and `N` denotes the number of points in each image. So the total number of points is `2MN` but for this case, the number of points are not constant for every image. Therefore this is not a function of `MN`.\n",
    "        - The estimated camera intrinsics and extrinsics are used in the project function for projecting 3D points into 2D image planes. \n",
    "        - It is necessary to transform 3D points in an arbitrary world frame to the camera’s local frame since every camera is at a different position.\n",
    "        - The point is first rotated from world frame to local camera frame to correct for rotation and then origin offset is corrected within this camera frame.\n",
    "        $$\n",
    "            \\mathbf{{}^{c}p} = R^{c}_{w}\\mathbf{{}^{w}p} + \\mathbf{{}^{c}t^{c}_{w}}\n",
    "         $$\n",
    "            The left superscript is the frame that contains the representation of the vector.\n",
    "\n",
    "        - The vector representations lying in different planes can not be directly added. Thus, point $\\mathbf{{}^{w}p}$ must be first rotated into the camera from before adding to $\\mathbf{{}^{c}t^{c}_{w}}$  since $\\mathbf{{}^{c}t^{c}_{w}}$ itself lies in the camera frame. So rotation can not be applied after translation.\n",
    "        - The equation of transformation if the translation was defined in the world frame -\n",
    "$$\n",
    "    \\mathbf{{}^{c}p} = R^{c}_{w}\\left(\\mathbf{{}^{w}p} + \\mathbf{{}^{w}t^{c}_{w}}\\right) = R^{c}_{w}\\mathbf{{}^{w}p} + R^{c}_{w}\\mathbf{{}^{w}t^{c}_{w}}\n",
    " $$\n",
    "\n",
    "        - The equation is difficult to optimize since it couples together the rotation and translation matrix. Otherwise, the product of R and t needs to be treated as a separate parameter. And thus we need to go back to the previous formulation as $R^{c}_{w}\\mathbf{{}^{w}t^{c}_{w}}$ is simply $\\mathbf{{}^{c}t^{c}_{w}}$)\n",
    "        \n",
    "5. `0.5 mark` **Jacobian** - `bundle_adjustment_sparsity()` function: m above is not \"M*N\" (*2) unlike our lecture notes. Why is that so?\n",
    "    - Ans-5 - Jacobian:\n",
    "        - The number of rows in a Jacobian matrix equals the number of residuals since each row corresponds to a residual. \n",
    "        - This is equal to the number of 2D points since the loss function computes the difference between the reprojected 2D points computed based on the estimated camera parameters and estimated 3D points and observed 2D points obtained from the images. \n",
    "        - As every 2D point contributes to an x and a y coordinate, the number of residuals is twice the number of 2D points. There are camera_indices.size number of 2D points as every element in camera_indices relates a 2D point to an image and so we have twice as many residuals in the Jacobian.\n",
    "\n",
    "6. `2 mark` **Jacobian & Parameters** - `bundle_adjustment_sparsity()` function: \n",
    "    1.  Why are we doing `n_cameras * 9` here instead of `n_cameras * 12`? Recollect: Every individual motion Jacobian was (1*)12 in our lecture notes. \n",
    "        - Ans 6.1 - Jacobian & Parameters: \n",
    "        - The camera parameters and 3D world point positions are optimised using Bundle adjustment.\n",
    "        - Thus the number of parameters that we optimise over is - *Number of camera parameters* $\\times$ *Number of cameras* $+$ *Number of coordinates* $\\times$ *Number of world points*\n",
    "         - In lecture notes we considered a 3 X 4 matrix that represents the camera projection matrix, then $P = K \\left[R | t \\right]$ matrix gives us 12 parameters for each camera. Since a 3 X 3 matrix was used to represent camera intrinsics and rotation matrices were also represented as 3 X 3 matrices.\n",
    "        - But here the number of camera parameters we have is \n",
    "            - 3 parameters representing axis-angle rotation\n",
    "            - 3 parameters representing a translation\n",
    "            - Focal length\n",
    "            - 2 distortion parameters\n",
    "            Thus, there is a total of 9 parameters.\n",
    "        - When we go from rotation matrices to axis-angles and camera intrinsic matrix to individual intrinsic properties, the number of parameters reduces from 12 to 9. \n",
    "\n",
    "    2. Ignoring the scale parameters, what was the number of unknown parameters in our lecture notes in terms of `n_cameras` and `n_points`? What is it here in the code? Is it different? If so, what is and why? [Link of notes](https://www.notion.so/Stereo-Structure-from-Motion-9fdd81e4194f4803ac9ba7552df56470).\n",
    "        - Ans 6.2 - Jacobian & Parameters:        \n",
    "            - Bundle adjustment optimizes the estimates of 3D world points (generated by structure from Motion frontend) and camera positions.\n",
    "            - Since we know the camera intrinsics, it can be concluded that the parameters we aim to optimise are 6 degrees of freedom per camera, that is 3 rotations and 3 translations and 3 degrees of freedom for every world point, that is its ($x$, $y$ and $z$) coordinates.\n",
    "            - Thus the total number of parameters to be estimated is -6 * `n_cameras` + 3 * `n_points`\n",
    "            - But the optimisation will have to be performed in SO(3) manifold instead of Euclidean space. For avoiding this situation, we can optimise the projection matrix as it is, essentially optimises the extrinsic and intrinsic parameters $P = K \\left[R | t \\right]$\n",
    "            - So the number of unknown parameters is  12 * `n_cameras` + 3 * `n_points`\n",
    "            - In this case, the intrinsic and extrinsic parameters are optimised separately. This is possible as rotation is represented using axis-angles.\n",
    "            - The number of parameters is 3 for translation, 3 for rotation (axis-angles) and 3 intrinsic parameters (for this case, otherwise there may be 5 intrinsic parameters). This gives us 9 parameters for each camera and a total of  9 * `n_cameras` + 3 * `n_points` parameters.\n",
    "            \n",
    "7. `6 mark` **Sparsity, Residual Vector & Jacobian** - `bundle_adjustment_sparsity()` function: Explain what you understand from above 6 lines of code by coding a simple toy example yourself to illustrate how it is different from what you've learnt in class. ([Coding toy example + elaborating in words]- both are compulsory.) For the toy example, you can take something like 3 points all seen from 3 cameras. (You don't actually have to code much, just need to call the existing function) Write that toy example after this cell\n",
    "    - Ans 7 - Sparsity, Residual Vector & Jacobian: \n",
    "**Structure of the Jacobian matrix** -\n",
    "- Each row corresponds to a residual.\n",
    "- Each column corresponds to a parameter to be optimised. The total number of columns is  9 * `n_cameras` + 3 * Number of world point parameters (since that is the number of parameters to be optimised)\n",
    "- There are 2 equations corresponding to each 2D point, one for its x coordinate and one for the y coordinate. Thus the number of residuals is twice the number of observations and so is the number of rows.\n",
    "- In the lecture notes, it was considered that N world points are visible in all M images, then we have 2MN rows. \n",
    "- The number of observations is `camera_ind.size` and we have twice as many rows.\n",
    "- The residuals may not appear in a particular order unlike the residuals considered in the lecture notes which were initially ordered according to points and then according to images. Random ordering works as long as a single ordering is maintained consistently.\n",
    "\n",
    "**The function of the code snippet** -\n",
    "- The elements of the Jacobian which are not always zero are marked using the code snippet. Thus `SciPy` solver can take advantage of the Jacobian matrix’s sparsity. \n",
    "- All the columns corresponding to the parameters of a camera are set to 1 using `Numpy`’s array indexing. \n",
    "- All the remaining elements are zero since those represent the cameras and world points not included in the observation. These zero elements contribute to the sparse structure of the matrix.\n",
    "- In the below code, in the theoretical setting, we define the structure of the Jacobian. However, in the practical setting, based on the dependant variables which are to be optimized (like, the 3D points and the camera parameters) we decide whether to set the value at an index to 1. Thus, the matrix will not be as structured as in the previous case. Also, the run time of the code will decrease due to the sparsity of the Jacobian matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theoretical sparse matrix\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "The practical sparse jacobian\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "camera_ind_exp = 10\n",
    "m = camera_ind_exp * 2\n",
    "B = np.zeros([m,16])\n",
    "B_prac = np.zeros([m,16])\n",
    "i = np.arange(camera_ind_exp)\n",
    "\n",
    "# theoretical setting\n",
    "B[2*i, np.array([0,0,0,0,0,  1,1,1,1,1])]=1\n",
    "B[2*i + 1, np.array([0,0,0,0,0,  1,1,1,1,1])]=1\n",
    "# practical setting\n",
    "B_prac[2*i, np.array([0,2,5,6,2,  1,9,14,7,11])]=1\n",
    "B_prac[2*i + 1, np.array([0,2,5,6,2,  1,9,14,7,11])]=1\n",
    "\n",
    "print(\"The theoretical sparse matrix\")\n",
    "print(B)\n",
    "print(\"The practical sparse jacobian\")\n",
    "print(B_prac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initializing R,t and 3D points for SfM given 2 images (`4 mark`)\n",
    "\n",
    "Using OpenCV functions, mention how you would initialize R,t (poses) and 3D points for SfM given 2 images and K matrix. You don't need to implement it, just mention function names with input/output arguments clearly and briefly explain what they do (You don't need to give detailed answers).\n",
    "\n",
    "1. First, we do feature matching using the following function calls:\n",
    "   ```python\n",
    "   sift = cv2.SIFT_create() # optional parameter nfeatures (number of features required)\n",
    "   keypoints1, descriptors1 = sift.detectAndCompute(img1, None) # None parameter is to specify no additional parameters\n",
    "   keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "   ```\n",
    "   `detectAndCompute()` returns the keypoints and their corresponding descriptors for the two input images. SURF or ORB features can also be used instead of SIFT. The corresponding features between the two images is then matched using K-Nearest-Neighbour based matching.\n",
    "   ```python\n",
    "   matcher = cv2.FlannBasedMatcher({'algorithm'=1, 'trees'=5}, {'checks'=32}) # algorithm 1 refers to KD-Tree\n",
    "   # initializing the kNN-based matcher with descriptors of the two images and k value\n",
    "   matches = matcher.knnMatch(descriptors1, descriptors2, k=2) # match the descriptors\n",
    "   ```\n",
    "   Points in the first image (`pts1`) and points in the second image (`pts2`)  are obtained by separating the matching points from `matches` as follows:\n",
    "   ```python\n",
    "   pts1 = np.array([keypoints1[match[0].queryIdx].pt for match in matches])\n",
    "   pts2 = np.array([keypoints2[match[0].trainIdx].pt for match in matches])\n",
    "   ```\n",
    "   To improve the quality of the matches, Lowe's Test can be used. For this, each keypoint of the first image is matched with a number of keypoints from the second image. The 2 best matches for each keypoint are kept (best matches are the ones with the smallest distance measurement). Lowe's test checks that the two distances are sufficiently different. If they are not, then the keypoint is discarded.\n",
    "<br/>\n",
    "2. We can find the essential matrix using `cv2.findEssentialMatrix`. The parameters to this function are the lists of matching points (`pts1` and `pts2`) and the camera intrinsics, calibration matrix `K`. The `method` parameter can be set to `cv2.RANSAC`, and RANSAC's threshold and probability values can be manipulated accordingly.  \n",
    "<br/>\n",
    "3. Now we can decompose the essential matrix into R,t as follows:\n",
    "\n",
    "    `Rt = cv2.recoverPose(E, pts1, pts2, K)`: This takes the Essential matrix E, the corresponding points in 2 images and the camera intrinsics matrix K as input parameters and returns R and t. `Rt[1]` gives us R and `Rt[2]` gives us t.  \n",
    "<br/>\n",
    "4. Using the camera extrinsics, R and t, we can find the 3D points as follows:  \n",
    "   ```python\n",
    "   P1 = K @ np.hstack((np.eye(3), np.zeros((3, 1)))) # first camera's extrinsic matrix is [I | 0]\n",
    "   P2 = K @ np.hstack((R, t)) # second camera's extrinsic matrix is [R | t]\n",
    "   ptsW = cv2.triangulatePoints(P1, P2, pts1, pts2) # triangulate back the points\n",
    "   ptsW /= ptsW[3] # homogenize\n",
    "   ptsW[:3] # world points\n",
    "   ```\n",
    "   The above calculation was done considering the first camera's frame. Therefore the obtained points are in 1st camera's frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
