{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo SLAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a major part of this project and will likely take some time. \n",
    "\n",
    "For stereo, feel free to look up existing tutorials that implement this and write your own code here. Do not spend too long tweaking parameters here, focus on getting decent results and move on. You can also use OpenCV functions to backproject to 3D. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: Stereo dense reconstruction\n",
    "\n",
    "3-D point clouds are very useful in robotics for several tasks such as object detection, motion estimation (3D-3D matching or 3D-2D matching), SLAM, and other forms of scene understanding.  Stereo camerasprovide  us  with  a  convenient  way  to  generate  dense  point  clouds. Dense here,  in  contrast  to sparse,means all the image points are used for the reconstruction.  In this part of the assignment you will be generating a dense 3D point cloud reconstruction of a scene from stereo images.\n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Generate a disparity map for each stereo pair.  Use OpenCV (e.g.  StereoSGBM) for this.  Notethat the images provided are already rectified and undistorted. </li>\n",
    "    <li> Then, using the camera parameters and baseline information generate colored point clouds from each disparity map.  Some points will have invalid disparity values, so ignore them.  Use [Open3D]for storing your point clouds. </li>\n",
    "    <li> Register (or transform) all the generated point clouds into your world frame by using the providedground truth poses. </li>\n",
    "    <li> Visualize the registered point cloud data, in color.  Use Open3D for this </li>\n",
    "</ol>\n",
    "    \n",
    "    \n",
    "Write briefly about how the disparity map is generated (if you used SGBM, write about SGBM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2021-12-03 03:30:12,491 - utils - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Script for storing the pcd in the mesh file \n",
    "ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar red\n",
    "property uchar green\n",
    "property uchar blue\n",
    "end_header\n",
    "'''\n",
    "def write_ply(fn, verts, colors):\n",
    "    verts = verts.reshape(-1, 3)\n",
    "    colors = colors.reshape(-1, 3)\n",
    "    verts = np.hstack([verts, colors])\n",
    "    with open(fn, 'wb') as f:\n",
    "        f.write((ply_header % dict(vert_num=len(verts))).encode('utf-8'))\n",
    "        np.savetxt(f, verts, fmt='%f %f %f %d %d %d ')\n",
    "\n",
    "## Reading poses file\n",
    "def read_poses(filename='../data/poses.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    T_21 = []\n",
    "    for i in range(len(lines)):\n",
    "        t = lines[i].split()\n",
    "        T = [] \n",
    "        T.append( [float(t[0]), float(t[1]),float(t[2]),float(t[3])] ) \n",
    "        T.append( [float(t[4]), float(t[5]),float(t[6]),float(t[7])] ) \n",
    "        T.append( [float(t[8]), float(t[9]),float(t[10]),float(t[11])]) \n",
    "        T.append([0,0,0,1])\n",
    "        T_21.append(np.array(T))\n",
    "    T_21 = np.asarray(T_21)\n",
    "    return T_21     \n",
    "\n",
    "## Reading calibration file\n",
    "def read_calib(filename='../data/calib.txt'):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    k = lines[1].split()\n",
    "    K = [] \n",
    "    K.append( [float(k[0]), float(k[1]),float(k[2])] ) \n",
    "    K.append( [float(k[3]), float(k[4]),float(k[5])] ) \n",
    "    K.append( [float(k[6]), float(k[7]),float(k[8])] )\n",
    "    K = np.asarray(K)\n",
    "    b = lines[4].split()\n",
    "    B = float(b[0]) \n",
    "    return K, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dir = '../data/img2/' \n",
    "right_dir = '../data/img3/'\n",
    "img_names = sorted(os.listdir(left_dir))\n",
    "num_images = len(img_names)\n",
    "TransMat_21 = read_poses()\n",
    "K, b = read_calib()\n",
    "focal_length = K[0][0]\n",
    "final_world_pts = []\n",
    "final_colors = []\n",
    "depth_maps_3D = []\n",
    "depth_maps_2D = []\n",
    "Q_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(num_images):\n",
    "    left_img = cv2.imread(left_dir + img_names[n])\n",
    "    right_img = cv2.imread(right_dir + img_names[n])\n",
    "    window_size = 5\n",
    "    min_disp = -39\n",
    "    num_disp = 144\n",
    "    stereo = cv2.StereoSGBM_create(minDisparity = min_disp,\n",
    "    numDisparities = num_disp,\n",
    "    disp12MaxDiff = 1,\n",
    "    blockSize = 5,\n",
    "    P1 = 8 * 3 * window_size ** 2,\n",
    "    P2 = 32 * 3 * window_size ** 2,\n",
    "    uniquenessRatio = 10,\n",
    "    speckleWindowSize = 100,\n",
    "    speckleRange = 32,\n",
    "    preFilterCap=63\n",
    "    )    \n",
    "    disparity_map = stereo.compute(left_img,right_img).astype(np.float32) / 64.0    \n",
    "    disparity_map = (disparity_map-min_disp)/num_disp\n",
    "    depth_maps_2D.append(disparity_map)\n",
    "    \n",
    "    n1, n2 = disparity_map.shape\n",
    "    \n",
    "    colors = cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB)\n",
    "    # Setting Q matrix \n",
    "    Q = np.asarray([[1, 0, 0, -0.5*n2],[0,-1, 0,  0.5*n1], [0, 0, 0, focal_length], [0, 0, 1/b,  0]])\n",
    "    \n",
    "    image_pts = []\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            image_pts.append(np.array([j,i,disparity_map[i][j],1]))\n",
    "    image_pts = np.array(image_pts)\n",
    "\n",
    "    points_3D = []\n",
    "    for pt in image_pts:\n",
    "        point = Q@pt\n",
    "        points_3D.append(point/point[3])\n",
    "    points_3D = np.asarray(points_3D) \n",
    "    depth_maps_3D.append(points_3D)\n",
    "    \n",
    "    points_world = TransMat_21[n]@points_3D.T\n",
    "    \n",
    "    mask = disparity_map >= disparity_map.min()\n",
    "    colors = colors[mask]\n",
    "    colors = colors / 255\n",
    "    for i in range(len(points_world[0])):\n",
    "        if(points_world[3][i]>0):\n",
    "            final_world_pts.append([points_world[0][i]/points_world[3][i],points_world[1][i]/points_world[3][i],points_world[2][i]/points_world[3][i]])\n",
    "            final_colors.append(colors[i])\n",
    "final_world_pts = np.asarray(final_world_pts)       \n",
    "final_colors = np.asarray(final_colors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(final_world_pts)\n",
    "pcd.colors = o3d.utility.Vector3dVector(final_colors)\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "\n",
    "final_colors_ = final_colors*255\n",
    "file_name = 'test.ply'\n",
    "write_ply(file_name, final_world_pts, final_colors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StereoSGBM\n",
    "StereoSGBM is the modified implementation of H. Hirschmuller algorithm. The algorithm matches blocks, not individual pixels, i.e., the algorithm uses Semi-Global Block Matching to calculate corresponding points and then measure their apparent positions' differences. The variant of the traditional algorithm using five dimensions (instead of eight) was implemented due to the memory requirement of 8 direction algorithm, meaning the algorithm is a single pass. The disparity values were negative, so we shifted it by min_disp. The parameters were tuned to get a smooth disparity map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: Motion estimation using iterative PnP\n",
    "\n",
    "Using the generated reconstruction from the previous part, synthesize a new image taken by a virtualmonocular camera fixed at any arbitrary position and orientation.  Your task in this part is to recover this pose using an iterative Perspective-from-n-Points (PnP) algorithm. \n",
    "\n",
    "#### Procedure: \n",
    "\n",
    "<ol>\n",
    "    <li> Obtain a set of 2D-3D correspondences between the the image and the point cloud.  Since hereyou’re generating the image, this should be easy to obtain. </li>\n",
    "    <li> For this set of correspondences compute the total reprojection error c= $\\sum_{i} ‖x_i−P_{k}X_i‖^2 $    where $P_{k}= K[R_{k}|t_{k}]$, $X_{i}$ is the 3D point in the world frame, $x_{i}$ is its corresponding projection. </li>\n",
    "    <li> Solve for the pose $T_{k}$ that minimizes this non-linear reprojection error using a Gauss-Newton (GN)scheme.  Recall that in GN we start with some initial estimated value $x_{o}$ and iteratively refine the estimate using $x_{1}$= $∆x+x_0$, where $∆x$ is obtained by solving the normal equations $J^{T}J∆x$= -$J^{T}e$, until convergence.The main steps in this scheme are computing the corresponding Jacobians and updating the estimates correctly.  For our problem,  use a 12×1 vector parameterization for $T_{k}$(the top 3×4submatrix).  Run the optimization for different choices of initialization and report your observations. </li>\n",
    "</ol>\n",
    "\n",
    "Make sure that you write about how you calculate the residual and jacobians. Do not just include the code. The pose that you have been given is the ground truth, so using that will obviously give good results for optimization, so try out something else as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "### getting the ground truth\n",
    "Q1 = np.array([ [-9.1e-01, 5.5e-02, -4.2e-01, -1.9e+02],\n",
    "               [4.2e-02, 9.983072e-01, 4.2e-02, 1.7e+00],\n",
    "               [4.2e-01, 2.1e-02, -9.2e-01, 5.5e+01],\n",
    "              [0,0,0,1]])\n",
    "Q1 = np.linalg.inv(Q1)\n",
    "Q = Q1[:3,:]\n",
    "P_gt = K@Q\n",
    "print(P_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-23.97346323 371.93543088   1.        ]\n",
      " [-22.95313021 371.93274661   1.        ]\n",
      " [-21.93281568 371.93006239   1.        ]\n",
      " ...\n",
      " [168.5358275  363.30194364   1.        ]\n",
      " [169.55268396 363.29934202   1.        ]\n",
      " [170.01022198 363.37033753   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Getting correspondances\n",
    "ind = range(0,10000)\n",
    "points_3d = []\n",
    "points_2d = []\n",
    "ones = np.ones((len(final_world_pts),1))\n",
    "final_world_pts_homo = np.concatenate((final_world_pts,ones),axis = 1 ) \n",
    "proj_gt = P_gt@(final_world_pts_homo.T)\n",
    "proj_gt = proj_gt/proj_gt[2,:]\n",
    "proj_gt = proj_gt.T\n",
    "\n",
    "for i in ind:\n",
    "    points_3d.append(final_world_pts_homo[i])\n",
    "    points_2d.append(proj_gt[i])\n",
    "points_3d = np.array(points_3d)\n",
    "points_2d = np.array(points_2d)\n",
    "print(points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Matrix P is found through DLT is: \n",
      "[[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "### Initialising P: 1.Random 2.DLT\n",
    "def DLT(x,X):\n",
    "    M = [];\n",
    "    zeros = np.zeros(4);\n",
    "    L = len(X);\n",
    "    for i in range(L):\n",
    "        M.append(np.hstack((-X[i],np.hstack((zeros,x[i][0]*X[i])))));\n",
    "        M.append(np.hstack((zeros,np.hstack((-X[i],x[i][1]*X[i])))));\n",
    "    M = np.array(M).reshape(2*L,12);\n",
    "    U,D,VT= np.linalg.svd(M);\n",
    "    P = np.array(VT[-1]).reshape(3,4);\n",
    "    P = P/P[-1,-1]\n",
    "    return P/P[-1,-1]\n",
    "print(\"The Matrix P is found through DLT is: \")\n",
    "P_dlt = DLT(points_2d[0:2000],points_3d[0:2000])*P_gt[2,3]\n",
    "print(P_dlt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Guass_Newton(P_est, points_3d, points_2d, itr, tol):\n",
    "    curr_itr = 0\n",
    "    flg = 1\n",
    "    lr = 1\n",
    "    while (flg==1):\n",
    "        jac = []\n",
    "        points_est = []\n",
    "        P_final = P_est\n",
    "        for pt in points_3d:\n",
    "            pp = P_final @ pt\n",
    "            j = [pt[0]/pp[2],pt[1]/pp[2],pt[2]/pp[2],pt[3]/pp[2],0,0,0,0,(-pp[0]*pt[0])/(pp[2]*pp[2]),-pp[0]*pt[1]/(pp[2]*pp[2]),-pp[0]*pt[2]/(pp[2]*pp[2]),-pp[0]*pt[3]/(pp[2]*pp[2])]\n",
    "            jac.append(np.array(j))\n",
    "            j = [0,0,0,0,pt[0]/(pp[2]),pt[1]/(pp[2]),pt[2]/(pp[2]),pt[3]/(pp[2]),-pp[1]*pt[0]/(pp[2]*pp[2]),-pp[1]*pt[1]/(pp[2]*pp[2]),-pp[1]*pt[2]/(pp[2]*pp[2]),-pp[1]*pt[3]/(pp[2]*pp[2])]\n",
    "            jac.append(np.array(j))\n",
    "            pp = pp/pp[2]\n",
    "            points_est.append(pp.T)\n",
    "        jac = np.array(jac)\n",
    "        points_est = np.array(points_est)\n",
    "        er = []\n",
    "        for i in range(len(points_est)):\n",
    "            er.append(points_2d[i][0]-points_est[i][0])\n",
    "            er.append(points_2d[i][1]-points_est[i][1])\n",
    "        er = np.array(er)\n",
    "        er = er.reshape(2*len(points_est),1)\n",
    "        gg = np.linalg.pinv(jac.T@jac)\n",
    "        P_final = P_final.reshape(12,1)\n",
    "        update = gg@(jac.T@er)\n",
    "        P_est = P_final + lr*update\n",
    "        up = P_est - P_final\n",
    "        diff = np.sqrt(up.T@up)\n",
    "        P_est = P_est.reshape(3,4)\n",
    "        P_final = P_final.reshape(3,4)\n",
    "        er_2 = (er.T@er)\n",
    "        curr_itr = curr_itr + 1\n",
    "#         if(curr_itr % 10 == 0):\n",
    "#             print(curr_itr,\"iterations done\")\n",
    "        if(np.linalg.norm(jac.T@er) < tol):\n",
    "#             print(curr_itr,\"iterations done\")\n",
    "            itr_req = curr_itr\n",
    "            print(\"Error in estimate: \"+ str(diff))\n",
    "            flg = 0\n",
    "        if(curr_itr > itr):\n",
    "#             print(curr_itr,\"iterations done\")\n",
    "            print(\"Error in estimate: \"+ str(diff))\n",
    "            itr_req = curr_itr\n",
    "            flg = 0\n",
    "    \n",
    "    return P_final, er_2, itr_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in estimate: [[3.23026787e-11]]\n",
      "Iterations required;  5\n",
      "P from Gauss-Newton: \n",
      " [[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n",
      "True P:\n",
      " [[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Initialising DLT output (best initialization)\n",
    "P_GN, error, itr_req = Guass_Newton(P_dlt, points_3d, points_2d, itr=100, tol=1e-7)\n",
    "print(\"Iterations required; \", itr_req)\n",
    "print(\"P from Gauss-Newton: \\n\", P_GN)\n",
    "print(\"True P:\\n\", P_gt)\n",
    "# print(\"Error: \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in estimate: [[3.11860937e-13]]\n",
      "Iterations required;  101\n",
      "P from Gauss-Newton: \n",
      " [[ 3.05963041e+01 -1.86410970e+00  8.48368615e+00  5.34986404e+03]\n",
      " [ 1.24910513e+00 -2.45765301e+01  5.16404746e+00 -4.91253457e+00]\n",
      " [ 1.41944664e-02 -1.43197507e-03  3.08978747e-02  9.99999865e-01]]\n",
      "True P:\n",
      " [[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Initialisation converging at another local minima\n",
    "P_est = np.array([[ 3.05963083e+01, -1.86410995e+00,  0.48368729e+00,  5.34986476e+03],\n",
    " [ 1.24910530e+00, -2.45765334e+01,  5.16404815e+00, -4.91253523e+00],\n",
    " [ 1.41944683e-02, -1.43197526e-03,  3.08978789e-02,  1.00000000e+00]])\n",
    "P_GN, error, itr_req = Guass_Newton(P_est, points_3d, points_2d, itr=100, tol=1e-7)\n",
    "print(\"Iterations required; \", itr_req)\n",
    "print(\"P from Gauss-Newton: \\n\", P_GN)\n",
    "print(\"True P:\\n\", P_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in estimate: [[297576.52537751]]\n",
      "Iterations required;  101\n",
      "P from Gauss-Newton: \n",
      " [[-4.22621366e+06  8.88269478e+06  5.16835399e+06  1.26547534e+07]\n",
      " [-2.93823718e+06  5.96280879e+06  3.52104387e+06  5.60941942e+06]\n",
      " [-1.15276747e+04  2.24065415e+04  3.91040650e+03 -1.05657080e+07]]\n",
      "True P:\n",
      " [[-8.88191631e+02  5.41139423e+01 -2.46276119e+02 -1.55303217e+05]\n",
      " [-3.62607430e+01  7.13441345e+02 -1.49909078e+02  1.42607815e+02]\n",
      " [-4.12056509e-01  4.15693433e-02 -8.96946037e-01 -2.90293725e+01]]\n"
     ]
    }
   ],
   "source": [
    "## Far initialisation which won't converge to ground truth \n",
    "P_est = np.array([[-7.97699140e-04, -1.56731843e-03, -9.64602229e-04,  5.53706762e-02],\n",
    "                 [-1.68118921e-04,  4.15993556e-03,  1.04888333e-03,  5.32315076e-02],\n",
    "                 [-1.05955850e-04, -9.42056054e-04, -2.61847498e-04,  1.00000000e+00]])\n",
    "P_GN, error, itr_req = Guass_Newton(P_est, points_3d, points_2d, itr=100, tol=1e-7)\n",
    "print(\"Iterations required; \", itr_req)\n",
    "print(\"P from Gauss-Newton: \\n\", P_GN)\n",
    "print(\"True P:\\n\", P_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <figure> -->\n",
    "<img src='../data/q2.jpeg' alt=drawing width=500 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "1. Using DLT output as initialization gives us better results and converges faster.\n",
    "2. If the initialization is close to a local maximum, the algorithm will converge to that minima and thus not obtain the optimal configuration.\n",
    "3. A wrong initialization may lead to no solution in fewer iterations.\n",
    "4. Thus Iterative PnP is helpful to recover the poses given the 3D-2D correspondences with good initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: Odometry Calculation\n",
    "\n",
    "In part 1, you used the ground truth pose for registration. Here, try to estimate the pose using the RGB image data alone. \n",
    "\n",
    "#### Procedure:\n",
    "\n",
    "1. This can be done by computing features across the two images and matching them. Since you already have the depth map, you now have correspondences between the depth maps of two images as well from the RGB feature matches. \n",
    "2. You can now convert this depth map to a point cloud.\n",
    "3. Since you have correspondences between image points in the depth map, you have 3D correspondences here as well. Perform ICP here to get a good pose estimate.\n",
    "4. Feed these initial pose estimates into the PnP pipeline and optimise further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for n in range(num_images - 1):\n",
    "    query_img = cv2.imread(left_dir + img_names[n])\n",
    "    train_img = cv2.imread(left_dir + img_names[n+1])  \n",
    "\n",
    "    query_img_bw = cv2.cvtColor(query_img,cv2.COLOR_BGR2GRAY)\n",
    "    train_img_bw = cv2.cvtColor(train_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    queryKeypoints, queryDescriptors = orb.detectAndCompute(query_img_bw,None)\n",
    "    trainKeypoints, trainDescriptors = orb.detectAndCompute(train_img_bw,None)\n",
    "\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.match(queryDescriptors,trainDescriptors)\n",
    "\n",
    "    list_kp1 = [queryKeypoints[mat.queryIdx].pt for mat in matches] \n",
    "    list_kp2 = [trainKeypoints[mat.trainIdx].pt for mat in matches]\n",
    "    list1.append(list_kp1)\n",
    "    list2.append(list_kp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cost(p, q):\n",
    "    r = np.sum(np.linalg.norm(p - q, axis=1)**2)/p.shape[0]\n",
    "    return r\n",
    "\n",
    "def ICP(p, q):\n",
    "    p_ = p - np.mean(p, axis = 0)\n",
    "    q_ = q - np.mean(q, axis = 0)\n",
    "    W = np.dot(p_.T, q_)/p.shape[0]\n",
    "    U, S, VT = np.linalg.svd(W)\n",
    "    sigma = np.eye(3)\n",
    "    sigma[2,2] = np.linalg.det(U)*np.linalg.det(VT.T)\n",
    "    R = np.dot(VT.T,U.T)\n",
    "    \n",
    "    if(np.linalg.det(U) < 0):\n",
    "        R = np.dot(VT.T, np.dot(sigma,U.T)) \n",
    "    t = np.mean(q, axis = 0) - R@np.mean(p, axis = 0)\n",
    "    return R, t\n",
    "\n",
    "def procrustes_alignment(p, q):\n",
    "    num_iter = 1\n",
    "    tol = 1e-15\n",
    "    q0 = q\n",
    "    cost = np.zeros((1, num_iter))\n",
    "    for i in range(num_iter):\n",
    "        cost[0, i] = find_cost(p, q)\n",
    "        R, t = ICP(p, q)\n",
    "        t = np.reshape(t, (3,1))\n",
    "        p = np.dot(R, p.T) + t\n",
    "        p = p.T\n",
    "        if(np.linalg.norm(p - q0) < tol):\n",
    "            print(np.linalg.norm(p - q0))\n",
    "            break\n",
    "    return R, t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ICP = []\n",
    "t_ICP = []\n",
    "T_ICP = []\n",
    "R_curr = np.eye(3)\n",
    "T_curr = np.eye(4)\n",
    "for n in range(num_images - 1):\n",
    "    pc1 = []\n",
    "    pc2 = []\n",
    "    for nn in range(500):\n",
    "        x_l1 = int(list1[n][nn][0])\n",
    "        x_l2 = int(list2[n][nn][0])\n",
    "        y_l1 = int(list1[n][nn][1])\n",
    "        y_l2 = int(list2[n][nn][1])\n",
    "        pc1.append(depth_maps_3D[n][(y_l1*n2 + x_l1), :3])\n",
    "        pc2.append(depth_maps_3D[n+1][(y_l2*n2 + x_l2), :3])\n",
    "    pc1 = np.array(pc1)\n",
    "    pc2 = np.array(pc2)  \n",
    "    R, t = procrustes_alignment(pc1, pc2)\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    t = t.reshape((3,))\n",
    "    T[:3, 3] = t\n",
    "    T_curr = T_curr@T\n",
    "    T_ICP.append(T_curr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ini = []\n",
    "T1 = np.eye(4)\n",
    "P1 = K@T1[:3, :]\n",
    "P_ini.append(P1)\n",
    "for i in range(num_images - 1):\n",
    "    Pini = K@T_ICP[i][:3, :]\n",
    "    P_ini.append(Pini)\n",
    "P_est = []\n",
    "\n",
    "depth_maps_2D_PnP = []\n",
    "for i in range(num_images):\n",
    "    o = P_ini[i]@(depth_maps_3D[i][:10000, :].T)\n",
    "    o = o/o[2,:]\n",
    "    o = o.T\n",
    "    depth_maps_2D_PnP.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For pose  1 :\n",
      "Error in estimate: [[1.576881e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[707.0912   0.     601.8873   0.    ]\n",
      " [  0.     707.0912 183.1104   0.    ]\n",
      " [  0.       0.       1.       0.    ]] \n",
      "\n",
      "For pose  2 :\n",
      "Error in estimate: [[9.914969e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 6.82364870e+02 -5.22417586e+01  6.27610763e+02  2.66226628e+04]\n",
      " [-1.05927029e+01  6.88228918e+02  2.44409769e+02 -7.32932021e+04]\n",
      " [-4.01229422e-02 -8.80203747e-02  9.95310285e-01  1.60863600e+01]] \n",
      "\n",
      "For pose  3 :\n",
      "Error in estimate: [[2.12345441e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 6.91079370e+02 -3.63015881e+01  6.19142783e+02  5.85111560e+04]\n",
      " [-1.24334710e+01  6.92320075e+02  2.32477325e+02 -6.37046301e+04]\n",
      " [-2.61327422e-02 -7.08177679e-02  9.97146892e-01 -5.08426762e+00]] \n",
      "\n",
      "For pose  4 :\n",
      "Error in estimate: [[6.73072024e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 7.16152956e+02 -2.19548804e+01  5.90668446e+02  1.31011721e+05]\n",
      " [ 7.34142475e+00  7.01381821e+02  2.03757279e+02 -2.99758149e+04]\n",
      " [ 1.52159556e-02 -2.94371541e-02  9.99450814e-01 -2.84506889e+01]] \n",
      "\n",
      "For pose  5 :\n",
      "Error in estimate: [[1.82626825e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[ 7.20023051e+02  7.37932154e+01  5.81693780e+02  1.67895699e+05]\n",
      " [-2.67978220e+00  7.23392104e+02  1.01015176e+02  1.00388211e+05]\n",
      " [ 2.18174942e-02  1.14519458e-01  9.93181399e-01 -5.58894091e+01]] \n",
      "\n",
      "For pose  6 :\n",
      "Error in estimate: [[4.37997423e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 7.56526110e+02  2.53412599e+01  5.37840453e+02  2.48887540e+05]\n",
      " [ 1.85598830e+01  7.15619568e+02  1.45091516e+02  4.83282457e+04]\n",
      " [ 8.65502529e-02  5.19177996e-02  9.94893761e-01 -7.13298423e+01]] \n",
      "\n",
      "For pose  7 :\n",
      "Error in estimate: [[1.2332069e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[ 7.67069775e+02  2.56952477e+00  5.23300721e+02  2.48372044e+05]\n",
      " [ 1.82350519e+01  7.07551279e+02  1.80405248e+02  8.77825194e+02]\n",
      " [ 1.06310144e-01  2.52916511e-03  9.94329803e-01 -1.01176629e+02]] \n",
      "\n",
      "For pose  8 :\n",
      "Error in estimate: [[1.91078263e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[ 7.73929759e+02  3.03964133e-01  5.13107126e+02  2.43297211e+05]\n",
      " [ 2.95278469e+01  7.09782735e+02  1.69835093e+02  1.59952988e+04]\n",
      " [ 1.19541524e-01  1.54749329e-02  9.92708593e-01 -1.09101472e+02]] \n",
      "\n",
      "For pose  9 :\n",
      "Error in estimate: [[8.92055536e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.39764693e+02 -1.59310965e+01  3.95964325e+02  3.62059506e+05]\n",
      " [ 5.59752446e+01  7.03601578e+02  1.87933432e+02 -1.34089213e+04]\n",
      " [ 2.61335781e-01 -1.83166605e-02  9.65074147e-01 -7.03718764e+01]] \n",
      "\n",
      "For pose  10 :\n",
      "Error in estimate: [[1.92848617e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.92141424e+02 -2.27292506e+01  2.56541124e+02  5.59161941e+05]\n",
      " [ 8.60999773e+01  6.99407540e+02  1.92154289e+02 -2.66634335e+04]\n",
      " [ 4.11866578e-01 -3.90189962e-02  9.10408392e-01  1.44307289e+01]] \n",
      "\n",
      "For pose  11 :\n",
      "Error in estimate: [[1.31024633e-10]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.07410252e+02 -1.24023167e+01  1.96720877e+02  6.14238439e+05]\n",
      " [ 8.13444948e+01  6.88980361e+02  2.28465576e+02 -7.87773781e+04]\n",
      " [ 4.71862995e-01 -8.10640125e-02  8.77937321e-01  7.16230508e+01]] \n",
      "\n",
      "For pose  12 :\n",
      "Error in estimate: [[1.5985031e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.27851250e+02 -3.58722066e+01 -7.17845914e+00  8.70231735e+05]\n",
      " [ 1.46707124e+02  6.74526535e+02  2.38743288e+02 -9.48823287e+04]\n",
      " [ 6.49273353e-01 -1.34687278e-01  7.48534201e-01  2.51055929e+02]] \n",
      "\n",
      "For pose  13 :\n",
      "Error in estimate: [[1.10948563e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.01319700e+02 -6.39140362e+01 -2.13972150e+02  1.14707263e+06]\n",
      " [ 2.23361157e+02  6.56385122e+02  2.29729731e+02 -8.89166684e+04]\n",
      " [ 7.91668950e-01 -1.93275060e-01  5.79573139e-01  4.84299845e+02]] \n",
      "\n",
      "For pose  14 :\n",
      "Error in estimate: [[9.55710189e-12]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.09529090e+02 -4.45174880e+01 -1.81717678e+02  1.08385084e+06]\n",
      " [ 2.08179423e+02  6.42532563e+02  2.78065851e+02 -1.88065643e+05]\n",
      " [ 7.70209053e-01 -2.23135073e-01  5.97485358e-01  4.01014243e+02]] \n",
      "\n",
      "For pose  15 :\n",
      "Error in estimate: [[3.05388215e-12]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.17048199e+02 -3.93239148e+01 -1.40436878e+02  9.64227180e+05]\n",
      " [ 1.89578846e+02  6.51340156e+02  2.70782654e+02 -2.08344005e+05]\n",
      " [ 7.45161387e-01 -2.00213082e-01  6.36120452e-01  2.77032128e+02]] \n",
      "\n",
      "For pose  16 :\n",
      "Error in estimate: [[2.65275938e-14]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.93994740e+02 -4.94030698e+01 -2.46128072e+02  9.74113241e+05]\n",
      " [ 2.36253567e+02  6.30172048e+02  2.83857050e+02 -2.57233739e+05]\n",
      " [ 8.06478880e-01 -2.52584847e-01  5.34595840e-01  3.17593287e+02]] \n",
      "\n",
      "For pose  17 :\n",
      "Error in estimate: [[2.31036333e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.74225002e+02 -7.19406242e+01 -3.04633351e+02  9.49557263e+05]\n",
      " [ 2.59223588e+02  6.42858936e+02  2.30310450e+02 -2.14272242e+05]\n",
      " [ 8.40521853e-01 -2.29853627e-01  4.90602003e-01  2.80132226e+02]] \n",
      "\n",
      "For pose  18 :\n",
      "Error in estimate: [[7.19550865e-14]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.71656907e+02 -8.75520163e+01 -3.07888239e+02  9.75465418e+05]\n",
      " [ 2.55323268e+02  6.61079315e+02  1.76894184e+02 -1.39773755e+05]\n",
      " [ 8.47804497e-01 -1.83581690e-01  4.97519143e-01  2.82186622e+02]] \n",
      "\n",
      "For pose  19 :\n",
      "Error in estimate: [[3.54594615e-14]]\n",
      "P from Gauss-Newton: \n",
      " [[ 9.01254167e+02 -5.34740532e+01 -2.17089243e+02  7.76104202e+05]\n",
      " [ 2.13906071e+02  6.63879571e+02  2.16830561e+02 -2.25951895e+05]\n",
      " [ 7.97239938e-01 -1.70219233e-01  5.79166552e-01  7.49754991e+01]] \n",
      "\n",
      "For pose  20 :\n",
      "Error in estimate: [[4.63260803e-13]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.88492991e+02 -3.71058600e+01 -2.67300668e+02  7.34435671e+05]\n",
      " [ 2.28685967e+02  6.43744461e+02  2.58463113e+02 -3.10139156e+05]\n",
      " [ 8.25128713e-01 -2.17942745e-01  5.21213552e-01  6.23055260e+01]] \n",
      "\n",
      "For pose  21 :\n",
      "Error in estimate: [[3.25639644e-11]]\n",
      "P from Gauss-Newton: \n",
      " [[ 8.57499439e+02 -9.57762432e+01 -3.43173296e+02  7.74737055e+05]\n",
      " [ 2.71874567e+02  6.54840864e+02  1.75428180e+02 -2.16544704e+05]\n",
      " [ 8.63858133e-01 -2.02581950e-01  4.61204597e-01  8.66688333e+01]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (num_images):\n",
    "    print(\"For pose \", i+1, \":\")\n",
    "    P_GN, error, itr_req = Guass_Newton(P_ini[i], depth_maps_3D[i][:5000, :], depth_maps_2D_PnP[i], itr=200, tol=1e-7)\n",
    "    P_est.append(P_GN)\n",
    "    print(\"P from Gauss-Newton: \\n\", P_GN, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
